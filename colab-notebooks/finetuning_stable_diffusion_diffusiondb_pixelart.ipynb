{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPvaKt0qqDNFwvP1Hiq7lSJ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBYLdqslwrCh",
        "outputId": "b9fb950b-60e6-47b4-9e4d-42f78563b002"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri May 12 18:35:20 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    45W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trying to use diffusers library directly\n",
        "* Would need 32GB RAM for GPU --> Select A100 GPUs on Colab"
      ],
      "metadata": {
        "id": "UYGuGvbcI7ty"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vonfbmLl1lW",
        "outputId": "24f7a6d6-e27f-429a-98a8-1d3cd95a7cf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'diffusers'...\n",
            "remote: Enumerating objects: 26417, done.\u001b[K\n",
            "remote: Counting objects: 100% (287/287), done.\u001b[K\n",
            "remote: Compressing objects: 100% (125/125), done.\u001b[K\n",
            "remote: Total 26417 (delta 175), reused 238 (delta 140), pack-reused 26130\u001b[K\n",
            "Receiving objects: 100% (26417/26417), 32.11 MiB | 16.86 MiB/s, done.\n",
            "Resolving deltas: 100% (19187/19187), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/huggingface/diffusers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/diffusers\n",
        "!dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrddqCi_qOt8",
        "outputId": "74e3e8d0-946c-410a-bc87-d3a14637c350"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/diffusers\n",
            "CITATION.cff\t    docs      MANIFEST.in     scripts\t tests\n",
            "CODE_OF_CONDUCT.md  examples  PHILOSOPHY.md   setup.cfg  _typos.toml\n",
            "CONTRIBUTING.md     LICENSE   pyproject.toml  setup.py\t utils\n",
            "docker\t\t    Makefile  README.md       src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1KiSeQEqP-S",
        "outputId": "8a5b7f88-3b96-4c8e-e3b8-449af9d057bb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/diffusers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting importlib-metadata (from diffusers==0.17.0.dev0)\n",
            "  Downloading importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.17.0.dev0) (3.12.0)\n",
            "Collecting huggingface-hub>=0.13.2 (from diffusers==0.17.0.dev0)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.17.0.dev0) (1.22.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.17.0.dev0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.17.0.dev0) (2.27.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.17.0.dev0) (8.4.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.17.0.dev0) (2023.4.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.17.0.dev0) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.17.0.dev0) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.17.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.17.0.dev0) (23.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.17.0.dev0) (3.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.17.0.dev0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.17.0.dev0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.17.0.dev0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.17.0.dev0) (3.4)\n",
            "Building wheels for collected packages: diffusers\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.17.0.dev0-py3-none-any.whl size=965530 sha256=3b0b09f493665127257dcf898fe56c530c321fa1b3cb02c18b55f17d83d38a76\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7klp0i5y/wheels/95/c5/3b/e1b4269f8a2584de57e75f949a185b48fc4144e9a91fc9965a\n",
            "Successfully built diffusers\n",
            "Installing collected packages: importlib-metadata, huggingface-hub, diffusers\n",
            "Successfully installed diffusers-0.17.0.dev0 huggingface-hub-0.14.1 importlib-metadata-6.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/diffusers/examples/text_to_image\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nxgFRzamEeF",
        "outputId": "ed00d0eb-9444-426a-9419-347278467bee"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/diffusers/examples/text_to_image\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting accelerate>=0.16.0 (from -r requirements.txt (line 1))\n",
            "  Downloading accelerate-0.19.0-py3-none-any.whl (219 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.15.1+cu118)\n",
            "Collecting transformers>=4.25.1 (from -r requirements.txt (line 3))\n",
            "  Downloading transformers-4.29.1-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m111.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from -r requirements.txt (line 4))\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ftfy (from -r requirements.txt (line 5))\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (2.12.2)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (3.1.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (2.0.0+cu118)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 2)) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 2)) (8.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (16.0.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 3)) (0.14.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 3)) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=4.25.1->-r requirements.txt (line 3))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m120.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 3)) (4.65.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 4)) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets->-r requirements.txt (line 4))\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 4)) (1.5.3)\n",
            "Collecting xxhash (from datasets->-r requirements.txt (line 4))\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->-r requirements.txt (line 4))\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 4)) (2023.4.0)\n",
            "Collecting aiohttp (from datasets->-r requirements.txt (line 4))\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19 (from datasets->-r requirements.txt (line 4))\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->-r requirements.txt (line 5)) (0.2.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.54.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (3.4.3)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (0.40.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2->-r requirements.txt (line 7)) (2.1.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets->-r requirements.txt (line 4))\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets->-r requirements.txt (line 4))\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets->-r requirements.txt (line 4))\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets->-r requirements.txt (line 4))\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets->-r requirements.txt (line 4))\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 4)) (2022.7.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 6)) (3.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Installing collected packages: tokenizers, xxhash, multidict, ftfy, frozenlist, dill, async-timeout, yarl, responses, multiprocess, aiosignal, transformers, aiohttp, datasets, accelerate\n",
            "Successfully installed accelerate-0.19.0 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 frozenlist-1.3.3 ftfy-6.1.1 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 tokenizers-0.13.3 transformers-4.29.1 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-uImfSvnyqb",
        "outputId": "f9fe694e-68a3-4a1c-a41a-24d7988ee141"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.15.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.22.2-py2.py3-none-any.whl (203 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m203.3/203.3 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n",
            "Collecting pathtools (from wandb)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=7e4bc3d97c03e728cf4c73240ae2bf5e4523c0ba77a86f1645c1a1b80efccb3f\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.22.2 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U xformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pq4P7lh-UPbb",
        "outputId": "18ed55aa-21bf-4cc7-82b5-4bf3c4f3ee7c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xformers\n",
            "  Downloading xformers-0.0.19-cp310-cp310-manylinux2014_x86_64.whl (108.2 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m108.2/108.2 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers) (1.22.4)\n",
            "Collecting pyre-extensions==0.0.29 (from xformers)\n",
            "  Downloading pyre_extensions-0.0.29-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.10/dist-packages (from xformers) (2.0.0+cu118)\n",
            "Collecting typing-inspect (from pyre-extensions==0.0.29->xformers)\n",
            "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyre-extensions==0.0.29->xformers) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->xformers) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->xformers) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->xformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->xformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->xformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->xformers) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->xformers) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0->xformers) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0->xformers) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect->pyre-extensions==0.0.29->xformers)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, typing-inspect, pyre-extensions, xformers\n",
            "Successfully installed mypy-extensions-1.0.0 pyre-extensions-0.0.29 typing-inspect-0.8.0 xformers-0.0.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "PThqkq6_rPzv",
        "outputId": "9b90ab0b-2dcb-4657-ab56-e1db9a1be4d9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://stackoverflow.com/questions/74962932/not-able-to-select-an-option-on-google-colab\n",
        "!accelerate config default"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PK8ac-NdmZFP",
        "outputId": "17e315d1-bc04-45e6-e3cc-12d877722f76"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-12 18:38:15.766542: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "accelerate configuration saved at /root/.cache/huggingface/accelerate/default_config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global credential.helper store"
      ],
      "metadata": {
        "id": "IqFyQ1Zws1zd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBADYBSFmdCM",
        "outputId": "e0789e87-0d82-45d6-8a28-757b6ad7c77f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "    \n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid.\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LORA training script\n",
        "# note: resolution is 768 for stable-diffusion-2-1 model\n",
        "# added enable_xformers_memory_efficient_attention parameter\n",
        "%%bash\n",
        "accelerate launch --mixed_precision=\"fp16\" train_text_to_image_lora.py \\\n",
        "  --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-2-1\" \\\n",
        "  --dataset_name=\"jainr3/diffusiondb-pixelart\" --caption_column=\"text\" \\\n",
        "  --resolution=768 --random_flip \\\n",
        "  --train_batch_size=16 \\\n",
        "  --num_train_epochs=5 --checkpointing_steps=2000 \\\n",
        "  --learning_rate=1e-04 --lr_scheduler=\"constant\" --lr_warmup_steps=0 \\\n",
        "  --seed=42 \\\n",
        "  --output_dir=\"sd-diffusiondb-pixelart-model-lora\" \\\n",
        "  --validation_prompt=\"cute dragon creature\" --report_to=\"wandb\" \\\n",
        "  --push_to_hub --enable_xformers_memory_efficient_attention"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6onuaCfAT5Uo",
        "outputId": "59b1ae51-9b78-4055-abce-41569fd5c000"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset diffusiondb-pixelart/2k_random_1k to /root/.cache/huggingface/datasets/jainr3___diffusiondb-pixelart/2k_random_1k/0.9.1/1ca3d6efd0e30e8a95c29881cddbd2a4496e4a7283ad5e439923b2b7bb5c9317...\n",
            "/root/.cache/huggingface/datasets/downloads/167e795f20c532b70fb6346517e2ea5014a7c81db81c71b81ca936baa1f39054\n",
            "Dataset diffusiondb-pixelart downloaded and prepared to /root/.cache/huggingface/datasets/jainr3___diffusiondb-pixelart/2k_random_1k/0.9.1/1ca3d6efd0e30e8a95c29881cddbd2a4496e4a7283ad5e439923b2b7bb5c9317. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-05-12 18:39:36.387504: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-05-12 18:39:41.927943: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:258: FutureWarning: `logging_dir` is deprecated and will be removed in version 0.18.0 of ğŸ¤— Accelerate. Use `project_dir` instead.\n",
            "  warnings.warn(\n",
            "05/12/2023 18:39:45 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "\rDownloading (â€¦)cheduler_config.json:   0%|          | 0.00/345 [00:00<?, ?B/s]\rDownloading (â€¦)cheduler_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 345/345 [00:00<00:00, 1.86MB/s]\n",
            "{'variance_type', 'dynamic_thresholding_ratio', 'thresholding', 'sample_max_value', 'clip_sample_range'} was not found in config. Values will be initialized to default values.\n",
            "\rDownloading (â€¦)tokenizer/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]\rDownloading (â€¦)tokenizer/vocab.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.06M/1.06M [00:00<00:00, 1.25MB/s]\rDownloading (â€¦)tokenizer/vocab.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.06M/1.06M [00:00<00:00, 1.24MB/s]\n",
            "\rDownloading (â€¦)tokenizer/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]\rDownloading (â€¦)tokenizer/merges.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 525k/525k [00:00<00:00, 826kB/s]\rDownloading (â€¦)tokenizer/merges.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 525k/525k [00:00<00:00, 825kB/s]\n",
            "\rDownloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/460 [00:00<?, ?B/s]\rDownloading (â€¦)cial_tokens_map.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 460/460 [00:00<00:00, 3.50MB/s]\n",
            "\rDownloading (â€¦)okenizer_config.json:   0%|          | 0.00/824 [00:00<?, ?B/s]\rDownloading (â€¦)okenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 824/824 [00:00<00:00, 6.15MB/s]\n",
            "\rDownloading (â€¦)_encoder/config.json:   0%|          | 0.00/633 [00:00<?, ?B/s]\rDownloading (â€¦)_encoder/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 633/633 [00:00<00:00, 4.80MB/s]\n",
            "\rDownloading pytorch_model.bin:   0%|          | 0.00/1.36G [00:00<?, ?B/s]\rDownloading pytorch_model.bin:   2%|â–         | 31.5M/1.36G [00:00<00:05, 225MB/s]\rDownloading pytorch_model.bin:   5%|â–Œ         | 73.4M/1.36G [00:00<00:04, 320MB/s]\rDownloading pytorch_model.bin:  10%|â–ˆ         | 136M/1.36G [00:00<00:02, 438MB/s] \rDownloading pytorch_model.bin:  15%|â–ˆâ–        | 199M/1.36G [00:00<00:02, 497MB/s]\rDownloading pytorch_model.bin:  19%|â–ˆâ–‰        | 262M/1.36G [00:00<00:02, 531MB/s]\rDownloading pytorch_model.bin:  24%|â–ˆâ–ˆâ–       | 325M/1.36G [00:00<00:01, 553MB/s]\rDownloading pytorch_model.bin:  28%|â–ˆâ–ˆâ–Š       | 388M/1.36G [00:00<00:01, 566MB/s]\rDownloading pytorch_model.bin:  33%|â–ˆâ–ˆâ–ˆâ–      | 451M/1.36G [00:00<00:01, 572MB/s]\rDownloading pytorch_model.bin:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 514M/1.36G [00:00<00:01, 578MB/s]\rDownloading pytorch_model.bin:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 577M/1.36G [00:01<00:01, 582MB/s]\rDownloading pytorch_model.bin:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 640M/1.36G [00:01<00:01, 585MB/s]\rDownloading pytorch_model.bin:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 703M/1.36G [00:01<00:01, 587MB/s]\rDownloading pytorch_model.bin:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 765M/1.36G [00:01<00:01, 588MB/s]\rDownloading pytorch_model.bin:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 828M/1.36G [00:01<00:00, 590MB/s]\rDownloading pytorch_model.bin:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 891M/1.36G [00:01<00:00, 583MB/s]\rDownloading pytorch_model.bin:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 954M/1.36G [00:01<00:00, 576MB/s]\rDownloading pytorch_model.bin:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.02G/1.36G [00:01<00:00, 568MB/s]\rDownloading pytorch_model.bin:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1.08G/1.36G [00:01<00:00, 569MB/s]\rDownloading pytorch_model.bin:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.14G/1.36G [00:02<00:00, 572MB/s]\rDownloading pytorch_model.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1.21G/1.36G [00:02<00:00, 576MB/s]\rDownloading pytorch_model.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.27G/1.36G [00:02<00:00, 580MB/s]\rDownloading pytorch_model.bin:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1.33G/1.36G [00:02<00:00, 584MB/s]\rDownloading pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.36G/1.36G [00:02<00:00, 556MB/s]\n",
            "\rDownloading (â€¦)main/vae/config.json:   0%|          | 0.00/611 [00:00<?, ?B/s]\rDownloading (â€¦)main/vae/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 611/611 [00:00<00:00, 3.95MB/s]\n",
            "\rDownloading (â€¦)on_pytorch_model.bin:   0%|          | 0.00/335M [00:00<?, ?B/s]\rDownloading (â€¦)on_pytorch_model.bin:  19%|â–ˆâ–‰        | 62.9M/335M [00:00<00:00, 575MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 126M/335M [00:00<00:00, 580MB/s] \rDownloading (â€¦)on_pytorch_model.bin:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 189M/335M [00:00<00:00, 581MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 252M/335M [00:00<00:00, 583MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 315M/335M [00:00<00:00, 573MB/s]\rDownloading (â€¦)on_pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 335M/335M [00:00<00:00, 568MB/s]\n",
            "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "\rDownloading (â€¦)ain/unet/config.json:   0%|          | 0.00/939 [00:00<?, ?B/s]\rDownloading (â€¦)ain/unet/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 939/939 [00:00<00:00, 6.23MB/s]\n",
            "\rDownloading (â€¦)on_pytorch_model.bin:   0%|          | 0.00/3.46G [00:00<?, ?B/s]\rDownloading (â€¦)on_pytorch_model.bin:   2%|â–         | 62.9M/3.46G [00:00<00:06, 534MB/s]\rDownloading (â€¦)on_pytorch_model.bin:   4%|â–         | 126M/3.46G [00:00<00:06, 543MB/s] \rDownloading (â€¦)on_pytorch_model.bin:   5%|â–Œ         | 189M/3.46G [00:00<00:05, 546MB/s]\rDownloading (â€¦)on_pytorch_model.bin:   7%|â–‹         | 252M/3.46G [00:00<00:05, 548MB/s]\rDownloading (â€¦)on_pytorch_model.bin:   9%|â–‰         | 315M/3.46G [00:00<00:05, 549MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  11%|â–ˆ         | 377M/3.46G [00:00<00:05, 549MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  13%|â–ˆâ–        | 440M/3.46G [00:00<00:05, 548MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  15%|â–ˆâ–        | 503M/3.46G [00:00<00:05, 547MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  16%|â–ˆâ–‹        | 566M/3.46G [00:01<00:05, 538MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  18%|â–ˆâ–Š        | 629M/3.46G [00:01<00:05, 531MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  20%|â–ˆâ–‰        | 692M/3.46G [00:01<00:05, 528MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  22%|â–ˆâ–ˆâ–       | 755M/3.46G [00:01<00:05, 539MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  24%|â–ˆâ–ˆâ–       | 818M/3.46G [00:01<00:04, 544MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  25%|â–ˆâ–ˆâ–Œ       | 881M/3.46G [00:01<00:05, 511MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  27%|â–ˆâ–ˆâ–‹       | 933M/3.46G [00:01<00:05, 479MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  28%|â–ˆâ–ˆâ–Š       | 986M/3.46G [00:02<00:08, 309MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  30%|â–ˆâ–ˆâ–‰       | 1.03G/3.46G [00:02<00:07, 325MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  31%|â–ˆâ–ˆâ–ˆ       | 1.07G/3.46G [00:02<00:06, 344MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  32%|â–ˆâ–ˆâ–ˆâ–      | 1.11G/3.46G [00:02<00:06, 350MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  33%|â–ˆâ–ˆâ–ˆâ–      | 1.15G/3.46G [00:02<00:06, 363MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  35%|â–ˆâ–ˆâ–ˆâ–      | 1.20G/3.46G [00:02<00:06, 374MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.24G/3.46G [00:02<00:05, 377MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.28G/3.46G [00:02<00:05, 382MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.32G/3.46G [00:02<00:05, 386MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.37G/3.46G [00:03<00:05, 397MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.42G/3.46G [00:03<00:05, 399MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.46G/3.46G [00:03<00:05, 401MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.50G/3.46G [00:03<00:04, 399MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.55G/3.46G [00:03<00:04, 419MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.61G/3.46G [00:03<00:04, 453MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.68G/3.46G [00:03<00:03, 492MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.74G/3.46G [00:03<00:03, 521MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.80G/3.46G [00:03<00:03, 544MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.87G/3.46G [00:04<00:02, 561MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1.93G/3.46G [00:04<00:02, 572MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1.99G/3.46G [00:04<00:02, 581MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.06G/3.46G [00:04<00:02, 587MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.12G/3.46G [00:04<00:02, 590MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.18G/3.46G [00:04<00:02, 563MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.24G/3.46G [00:04<00:02, 417MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.30G/3.46G [00:05<00:03, 348MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.34G/3.46G [00:05<00:03, 306MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.38G/3.46G [00:05<00:03, 281MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.41G/3.46G [00:05<00:04, 262MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.44G/3.46G [00:05<00:04, 247MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.47G/3.46G [00:05<00:04, 242MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.51G/3.46G [00:06<00:04, 232MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.54G/3.46G [00:06<00:04, 224MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.57G/3.46G [00:06<00:04, 221MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.60G/3.46G [00:06<00:03, 226MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.63G/3.46G [00:06<00:03, 225MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.66G/3.46G [00:06<00:03, 230MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.69G/3.46G [00:06<00:03, 229MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.73G/3.46G [00:06<00:03, 235MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.77G/3.46G [00:07<00:02, 263MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2.81G/3.46G [00:07<00:02, 288MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2.84G/3.46G [00:07<00:02, 294MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2.87G/3.46G [00:07<00:01, 299MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2.90G/3.46G [00:07<00:01, 301MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2.94G/3.46G [00:07<00:01, 303MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2.99G/3.46G [00:07<00:01, 357MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.03G/3.46G [00:07<00:01, 365MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.08G/3.46G [00:07<00:00, 392MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.15G/3.46G [00:08<00:00, 437MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.21G/3.46G [00:08<00:00, 474MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.27G/3.46G [00:08<00:00, 502MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.33G/3.46G [00:08<00:00, 514MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.39G/3.46G [00:08<00:00, 512MB/s]\rDownloading (â€¦)on_pytorch_model.bin:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.44G/3.46G [00:08<00:00, 514MB/s]\rDownloading (â€¦)on_pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.46G/3.46G [00:08<00:00, 399MB/s]\n",
            "{'addition_embed_type', 'mid_block_only_cross_attention', 'resnet_time_scale_shift', 'conv_out_kernel', 'time_embedding_act_fn', 'mid_block_type', 'resnet_out_scale_factor', 'addition_embed_type_num_heads', 'timestep_post_act', 'cross_attention_norm', 'conv_in_kernel', 'resnet_skip_time_act', 'encoder_hid_dim', 'time_embedding_dim', 'time_embedding_type', 'projection_class_embeddings_input_dim', 'class_embeddings_concat', 'time_cond_proj_dim', 'class_embed_type'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.10/dist-packages/diffusers/models/attention_processor.py:192: UserWarning: You have specified using flash attention using xFormers but you have PyTorch 2.0 already installed. We will default to PyTorch's native efficient flash attention implementation provided by PyTorch 2.0.\n",
            "  warnings.warn(\n",
            "\rDownloading builder script:   0%|          | 0.00/12.2k [00:00<?, ?B/s]\rDownloading builder script: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12.2k/12.2k [00:00<00:00, 10.0MB/s]\n",
            "\rDownloading readme:   0%|          | 0.00/18.5k [00:00<?, ?B/s]\rDownloading readme: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18.5k/18.5k [00:00<00:00, 14.6MB/s]\n",
            "05/12/2023 18:40:21 - WARNING - datasets.builder - No config specified, defaulting to: diffusiondb-pixelart/2k_random_1k\n",
            "\rDownloading data:   0%|          | 0.00/9.42M [00:00<?, ?B/s]\rDownloading data:   0%|          | 17.4k/9.42M [00:00<01:52, 83.7kB/s]\rDownloading data:   1%|          | 59.4k/9.42M [00:00<01:01, 152kB/s] \rDownloading data:   1%|â–         | 139k/9.42M [00:00<00:36, 255kB/s] \rDownloading data:   3%|â–         | 313k/9.42M [00:00<00:18, 480kB/s]\rDownloading data:   7%|â–‹         | 662k/9.42M [00:01<00:09, 939kB/s]\rDownloading data:  14%|â–ˆâ–        | 1.34M/9.42M [00:01<00:04, 1.73MB/s]\rDownloading data:  29%|â–ˆâ–ˆâ–‰       | 2.71M/9.42M [00:01<00:02, 3.31MB/s]\rDownloading data:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 5.46M/9.42M [00:01<00:00, 6.44MB/s]\rDownloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 9.41M/9.42M [00:01<00:00, 9.90MB/s]\rDownloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.42M/9.42M [00:01<00:00, 4.94MB/s]\n",
            "\rDownloading data:   0%|          | 0.00/195M [00:00<?, ?B/s]\rDownloading data:   0%|          | 18.4k/195M [00:00<36:40, 88.4kB/s]\rDownloading data:   0%|          | 52.2k/195M [00:00<24:51, 130kB/s] \rDownloading data:   0%|          | 138k/195M [00:00<12:35, 257kB/s] \rDownloading data:   0%|          | 296k/195M [00:00<07:11, 450kB/s]\rDownloading data:   0%|          | 609k/195M [00:01<03:55, 823kB/s]\rDownloading data:   1%|          | 1.25M/195M [00:01<02:02, 1.58MB/s]\rDownloading data:   1%|â–         | 2.53M/195M [00:01<01:03, 3.03MB/s]\rDownloading data:   3%|â–         | 5.08M/195M [00:01<00:32, 5.92MB/s]\rDownloading data:   5%|â–         | 9.10M/195M [00:01<00:18, 9.95MB/s]\rDownloading data:   7%|â–‹         | 13.1M/195M [00:02<00:14, 12.7MB/s]\rDownloading data:   9%|â–‰         | 17.2M/195M [00:02<00:12, 14.6MB/s]\rDownloading data:  11%|â–ˆ         | 21.0M/195M [00:02<00:11, 15.5MB/s]\rDownloading data:  13%|â–ˆâ–        | 25.1M/195M [00:02<00:10, 16.6MB/s]\rDownloading data:  15%|â–ˆâ–        | 29.2M/195M [00:02<00:09, 17.3MB/s]\rDownloading data:  17%|â–ˆâ–‹        | 32.4M/195M [00:03<00:09, 16.6MB/s]\rDownloading data:  19%|â–ˆâ–Š        | 36.4M/195M [00:03<00:09, 17.3MB/s]\rDownloading data:  21%|â–ˆâ–ˆ        | 40.5M/195M [00:03<00:08, 17.9MB/s]\rDownloading data:  23%|â–ˆâ–ˆâ–       | 44.6M/195M [00:03<00:08, 18.2MB/s]\rDownloading data:  25%|â–ˆâ–ˆâ–       | 48.6M/195M [00:04<00:07, 18.4MB/s]\rDownloading data:  27%|â–ˆâ–ˆâ–‹       | 52.7M/195M [00:04<00:07, 18.6MB/s]\rDownloading data:  29%|â–ˆâ–ˆâ–‰       | 56.7M/195M [00:04<00:07, 18.6MB/s]\rDownloading data:  31%|â–ˆâ–ˆâ–ˆ       | 60.7M/195M [00:04<00:07, 18.6MB/s]\rDownloading data:  33%|â–ˆâ–ˆâ–ˆâ–      | 64.7M/195M [00:04<00:07, 18.5MB/s]\rDownloading data:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 68.7M/195M [00:05<00:06, 18.6MB/s]\rDownloading data:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 72.8M/195M [00:05<00:06, 18.8MB/s]\rDownloading data:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 76.9M/195M [00:05<00:06, 18.8MB/s]\rDownloading data:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 81.0M/195M [00:05<00:06, 18.9MB/s]\rDownloading data:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 85.1M/195M [00:05<00:05, 18.9MB/s]\rDownloading data:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 89.2M/195M [00:06<00:05, 19.0MB/s]\rDownloading data:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 93.2M/195M [00:06<00:05, 19.0MB/s]\rDownloading data:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 97.3M/195M [00:06<00:05, 19.0MB/s]\rDownloading data:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 101M/195M [00:06<00:04, 19.0MB/s] \rDownloading data:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 105M/195M [00:07<00:04, 18.9MB/s]\rDownloading data:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 109M/195M [00:07<00:04, 19.0MB/s]\rDownloading data:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 113M/195M [00:07<00:04, 18.8MB/s]\rDownloading data:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 118M/195M [00:07<00:04, 19.0MB/s]\rDownloading data:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 122M/195M [00:07<00:03, 19.0MB/s]\rDownloading data:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 126M/195M [00:08<00:03, 18.9MB/s]\rDownloading data:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 130M/195M [00:08<00:03, 18.9MB/s]\rDownloading data:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 134M/195M [00:08<00:03, 18.9MB/s]\rDownloading data:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 138M/195M [00:08<00:02, 18.9MB/s]\rDownloading data:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 142M/195M [00:08<00:02, 19.0MB/s]\rDownloading data:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 146M/195M [00:09<00:02, 18.9MB/s]\rDownloading data:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 150M/195M [00:09<00:02, 18.8MB/s]\rDownloading data:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 154M/195M [00:09<00:02, 18.9MB/s]\rDownloading data:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 158M/195M [00:09<00:01, 18.9MB/s]\rDownloading data:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 162M/195M [00:10<00:01, 18.8MB/s]\rDownloading data:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 166M/195M [00:10<00:01, 18.8MB/s]\rDownloading data:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 170M/195M [00:10<00:01, 18.8MB/s]\rDownloading data:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 174M/195M [00:10<00:01, 18.8MB/s]\rDownloading data:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 178M/195M [00:10<00:00, 18.8MB/s]\rDownloading data:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 182M/195M [00:11<00:00, 18.9MB/s]\rDownloading data:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 186M/195M [00:11<00:00, 18.9MB/s]\rDownloading data:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 191M/195M [00:11<00:00, 19.0MB/s]\rDownloading data:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 194M/195M [00:11<00:00, 17.4MB/s]\rDownloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 195M/195M [00:11<00:00, 16.5MB/s]\n",
            "\rGenerating train split: 0 examples [00:00, ? examples/s]\rGenerating train split: 1 examples [00:00,  1.04 examples/s]\rGenerating train split: 60 examples [00:01, 77.06 examples/s]\rGenerating train split: 122 examples [00:01, 160.97 examples/s]\rGenerating train split: 183 examples [00:01, 241.84 examples/s]\rGenerating train split: 245 examples [00:01, 318.55 examples/s]\rGenerating train split: 307 examples [00:01, 385.69 examples/s]\rGenerating train split: 369 examples [00:01, 441.28 examples/s]\rGenerating train split: 432 examples [00:01, 487.64 examples/s]\rGenerating train split: 494 examples [00:01, 522.51 examples/s]\rGenerating train split: 557 examples [00:01, 549.68 examples/s]\rGenerating train split: 621 examples [00:01, 570.43 examples/s]\rGenerating train split: 684 examples [00:02, 583.93 examples/s]\rGenerating train split: 748 examples [00:02, 594.94 examples/s]\rGenerating train split: 811 examples [00:02, 599.86 examples/s]\rGenerating train split: 875 examples [00:02, 606.69 examples/s]\rGenerating train split: 937 examples [00:02, 609.09 examples/s]\rGenerating train split: 999 examples [00:02, 610.73 examples/s]\r                                                               \r\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 860.90it/s]\n",
            "wandb: Currently logged in as: jainr3 (rahul96jain). Use `wandb login --relogin` to force relogin\n",
            "wandb: Tracking run with wandb version 0.15.2\n",
            "wandb: Run data is saved locally in /content/diffusers/examples/text_to_image/wandb/run-20230512_184045-gjqwiuda\n",
            "wandb: Run `wandb offline` to turn off syncing.\n",
            "wandb: Syncing run dutiful-sunset-6\n",
            "wandb: â­ï¸ View project at https://wandb.ai/rahul96jain/text2image-fine-tune\n",
            "wandb: ğŸš€ View run at https://wandb.ai/rahul96jain/text2image-fine-tune/runs/gjqwiuda\n",
            "05/12/2023 18:40:46 - INFO - __main__ - ***** Running training *****\n",
            "05/12/2023 18:40:46 - INFO - __main__ -   Num examples = 1000\n",
            "05/12/2023 18:40:46 - INFO - __main__ -   Num Epochs = 5\n",
            "05/12/2023 18:40:46 - INFO - __main__ -   Instantaneous batch size per device = 16\n",
            "05/12/2023 18:40:46 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "05/12/2023 18:40:46 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "05/12/2023 18:40:46 - INFO - __main__ -   Total optimization steps = 315\n",
            "\r  0%|          | 0/315 [00:00<?, ?it/s]\rSteps:   0%|          | 0/315 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()\n",
            "\rSteps:   0%|          | 1/315 [00:08<43:04,  8.23s/it]\rSteps:   0%|          | 1/315 [00:08<43:04,  8.23s/it, lr=0.0001, step_loss=0.235]\rSteps:   1%|          | 2/315 [00:10<24:13,  4.65s/it, lr=0.0001, step_loss=0.235]\rSteps:   1%|          | 2/315 [00:10<24:13,  4.65s/it, lr=0.0001, step_loss=0.249]\rSteps:   1%|          | 3/315 [00:12<17:29,  3.36s/it, lr=0.0001, step_loss=0.249]\rSteps:   1%|          | 3/315 [00:12<17:29,  3.36s/it, lr=0.0001, step_loss=0.278]\rSteps:   1%|â–         | 4/315 [00:14<14:21,  2.77s/it, lr=0.0001, step_loss=0.278]\rSteps:   1%|â–         | 4/315 [00:14<14:21,  2.77s/it, lr=0.0001, step_loss=0.226]\rSteps:   2%|â–         | 5/315 [00:15<12:37,  2.44s/it, lr=0.0001, step_loss=0.226]\rSteps:   2%|â–         | 5/315 [00:15<12:37,  2.44s/it, lr=0.0001, step_loss=0.304]\rSteps:   2%|â–         | 6/315 [00:17<11:32,  2.24s/it, lr=0.0001, step_loss=0.304]\rSteps:   2%|â–         | 6/315 [00:17<11:32,  2.24s/it, lr=0.0001, step_loss=0.237]\rSteps:   2%|â–         | 7/315 [00:19<10:50,  2.11s/it, lr=0.0001, step_loss=0.237]\rSteps:   2%|â–         | 7/315 [00:19<10:50,  2.11s/it, lr=0.0001, step_loss=0.246]\rSteps:   3%|â–         | 8/315 [00:21<10:25,  2.04s/it, lr=0.0001, step_loss=0.246]\rSteps:   3%|â–         | 8/315 [00:21<10:25,  2.04s/it, lr=0.0001, step_loss=0.249]\rSteps:   3%|â–         | 9/315 [00:23<10:05,  1.98s/it, lr=0.0001, step_loss=0.249]\rSteps:   3%|â–         | 9/315 [00:23<10:05,  1.98s/it, lr=0.0001, step_loss=0.242]\rSteps:   3%|â–         | 10/315 [00:25<09:50,  1.94s/it, lr=0.0001, step_loss=0.242]\rSteps:   3%|â–         | 10/315 [00:25<09:50,  1.94s/it, lr=0.0001, step_loss=0.223]\rSteps:   3%|â–         | 11/315 [00:27<09:42,  1.91s/it, lr=0.0001, step_loss=0.223]\rSteps:   3%|â–         | 11/315 [00:27<09:42,  1.91s/it, lr=0.0001, step_loss=0.246]\rSteps:   4%|â–         | 12/315 [00:28<09:36,  1.90s/it, lr=0.0001, step_loss=0.246]\rSteps:   4%|â–         | 12/315 [00:28<09:36,  1.90s/it, lr=0.0001, step_loss=0.288]\rSteps:   4%|â–         | 13/315 [00:30<09:29,  1.89s/it, lr=0.0001, step_loss=0.288]\rSteps:   4%|â–         | 13/315 [00:30<09:29,  1.89s/it, lr=0.0001, step_loss=0.265]\rSteps:   4%|â–         | 14/315 [00:32<09:24,  1.87s/it, lr=0.0001, step_loss=0.265]\rSteps:   4%|â–         | 14/315 [00:32<09:24,  1.87s/it, lr=0.0001, step_loss=0.231]\rSteps:   5%|â–         | 15/315 [00:34<09:19,  1.87s/it, lr=0.0001, step_loss=0.231]\rSteps:   5%|â–         | 15/315 [00:34<09:19,  1.87s/it, lr=0.0001, step_loss=0.26] \rSteps:   5%|â–Œ         | 16/315 [00:36<09:16,  1.86s/it, lr=0.0001, step_loss=0.26]\rSteps:   5%|â–Œ         | 16/315 [00:36<09:16,  1.86s/it, lr=0.0001, step_loss=0.234]\rSteps:   5%|â–Œ         | 17/315 [00:38<09:11,  1.85s/it, lr=0.0001, step_loss=0.234]\rSteps:   5%|â–Œ         | 17/315 [00:38<09:11,  1.85s/it, lr=0.0001, step_loss=0.26] \rSteps:   6%|â–Œ         | 18/315 [00:39<09:09,  1.85s/it, lr=0.0001, step_loss=0.26]\rSteps:   6%|â–Œ         | 18/315 [00:39<09:09,  1.85s/it, lr=0.0001, step_loss=0.232]\rSteps:   6%|â–Œ         | 19/315 [00:41<09:06,  1.85s/it, lr=0.0001, step_loss=0.232]\rSteps:   6%|â–Œ         | 19/315 [00:41<09:06,  1.85s/it, lr=0.0001, step_loss=0.263]\rSteps:   6%|â–‹         | 20/315 [00:43<09:06,  1.85s/it, lr=0.0001, step_loss=0.263]\rSteps:   6%|â–‹         | 20/315 [00:43<09:06,  1.85s/it, lr=0.0001, step_loss=0.282]\rSteps:   7%|â–‹         | 21/315 [00:45<09:06,  1.86s/it, lr=0.0001, step_loss=0.282]\rSteps:   7%|â–‹         | 21/315 [00:45<09:06,  1.86s/it, lr=0.0001, step_loss=0.235]\rSteps:   7%|â–‹         | 22/315 [00:47<09:05,  1.86s/it, lr=0.0001, step_loss=0.235]\rSteps:   7%|â–‹         | 22/315 [00:47<09:05,  1.86s/it, lr=0.0001, step_loss=0.267]\rSteps:   7%|â–‹         | 23/315 [00:49<09:03,  1.86s/it, lr=0.0001, step_loss=0.267]\rSteps:   7%|â–‹         | 23/315 [00:49<09:03,  1.86s/it, lr=0.0001, step_loss=0.307]\rSteps:   8%|â–Š         | 24/315 [00:51<08:57,  1.85s/it, lr=0.0001, step_loss=0.307]\rSteps:   8%|â–Š         | 24/315 [00:51<08:57,  1.85s/it, lr=0.0001, step_loss=0.187]\rSteps:   8%|â–Š         | 25/315 [00:52<08:58,  1.86s/it, lr=0.0001, step_loss=0.187]\rSteps:   8%|â–Š         | 25/315 [00:52<08:58,  1.86s/it, lr=0.0001, step_loss=0.28] \rSteps:   8%|â–Š         | 26/315 [00:54<08:54,  1.85s/it, lr=0.0001, step_loss=0.28]\rSteps:   8%|â–Š         | 26/315 [00:54<08:54,  1.85s/it, lr=0.0001, step_loss=0.24]\rSteps:   9%|â–Š         | 27/315 [00:56<08:53,  1.85s/it, lr=0.0001, step_loss=0.24]\rSteps:   9%|â–Š         | 27/315 [00:56<08:53,  1.85s/it, lr=0.0001, step_loss=0.269]\rSteps:   9%|â–‰         | 28/315 [00:58<08:51,  1.85s/it, lr=0.0001, step_loss=0.269]\rSteps:   9%|â–‰         | 28/315 [00:58<08:51,  1.85s/it, lr=0.0001, step_loss=0.182]\rSteps:   9%|â–‰         | 29/315 [01:00<08:49,  1.85s/it, lr=0.0001, step_loss=0.182]\rSteps:   9%|â–‰         | 29/315 [01:00<08:49,  1.85s/it, lr=0.0001, step_loss=0.22] \rSteps:  10%|â–‰         | 30/315 [01:02<08:47,  1.85s/it, lr=0.0001, step_loss=0.22]\rSteps:  10%|â–‰         | 30/315 [01:02<08:47,  1.85s/it, lr=0.0001, step_loss=0.225]\rSteps:  10%|â–‰         | 31/315 [01:04<08:44,  1.85s/it, lr=0.0001, step_loss=0.225]\rSteps:  10%|â–‰         | 31/315 [01:04<08:44,  1.85s/it, lr=0.0001, step_loss=0.304]\rSteps:  10%|â–ˆ         | 32/315 [01:05<08:43,  1.85s/it, lr=0.0001, step_loss=0.304]\rSteps:  10%|â–ˆ         | 32/315 [01:05<08:43,  1.85s/it, lr=0.0001, step_loss=0.225]\rSteps:  10%|â–ˆ         | 33/315 [01:07<08:42,  1.85s/it, lr=0.0001, step_loss=0.225]\rSteps:  10%|â–ˆ         | 33/315 [01:07<08:42,  1.85s/it, lr=0.0001, step_loss=0.264]\rSteps:  11%|â–ˆ         | 34/315 [01:09<08:42,  1.86s/it, lr=0.0001, step_loss=0.264]\rSteps:  11%|â–ˆ         | 34/315 [01:09<08:42,  1.86s/it, lr=0.0001, step_loss=0.224]\rSteps:  11%|â–ˆ         | 35/315 [01:11<08:40,  1.86s/it, lr=0.0001, step_loss=0.224]\rSteps:  11%|â–ˆ         | 35/315 [01:11<08:40,  1.86s/it, lr=0.0001, step_loss=0.266]\rSteps:  11%|â–ˆâ–        | 36/315 [01:13<08:37,  1.85s/it, lr=0.0001, step_loss=0.266]\rSteps:  11%|â–ˆâ–        | 36/315 [01:13<08:37,  1.85s/it, lr=0.0001, step_loss=0.209]\rSteps:  12%|â–ˆâ–        | 37/315 [01:15<08:35,  1.85s/it, lr=0.0001, step_loss=0.209]\rSteps:  12%|â–ˆâ–        | 37/315 [01:15<08:35,  1.85s/it, lr=0.0001, step_loss=0.266]\rSteps:  12%|â–ˆâ–        | 38/315 [01:17<08:33,  1.85s/it, lr=0.0001, step_loss=0.266]\rSteps:  12%|â–ˆâ–        | 38/315 [01:17<08:33,  1.85s/it, lr=0.0001, step_loss=0.192]\rSteps:  12%|â–ˆâ–        | 39/315 [01:18<08:31,  1.85s/it, lr=0.0001, step_loss=0.192]\rSteps:  12%|â–ˆâ–        | 39/315 [01:18<08:31,  1.85s/it, lr=0.0001, step_loss=0.218]\rSteps:  13%|â–ˆâ–        | 40/315 [01:20<08:29,  1.85s/it, lr=0.0001, step_loss=0.218]\rSteps:  13%|â–ˆâ–        | 40/315 [01:20<08:29,  1.85s/it, lr=0.0001, step_loss=0.189]\rSteps:  13%|â–ˆâ–        | 41/315 [01:22<08:27,  1.85s/it, lr=0.0001, step_loss=0.189]\rSteps:  13%|â–ˆâ–        | 41/315 [01:22<08:27,  1.85s/it, lr=0.0001, step_loss=0.224]\rSteps:  13%|â–ˆâ–        | 42/315 [01:24<08:26,  1.86s/it, lr=0.0001, step_loss=0.224]\rSteps:  13%|â–ˆâ–        | 42/315 [01:24<08:26,  1.86s/it, lr=0.0001, step_loss=0.272]\rSteps:  14%|â–ˆâ–        | 43/315 [01:26<08:25,  1.86s/it, lr=0.0001, step_loss=0.272]\rSteps:  14%|â–ˆâ–        | 43/315 [01:26<08:25,  1.86s/it, lr=0.0001, step_loss=0.224]\rSteps:  14%|â–ˆâ–        | 44/315 [01:28<08:21,  1.85s/it, lr=0.0001, step_loss=0.224]\rSteps:  14%|â–ˆâ–        | 44/315 [01:28<08:21,  1.85s/it, lr=0.0001, step_loss=0.272]\rSteps:  14%|â–ˆâ–        | 45/315 [01:30<08:21,  1.86s/it, lr=0.0001, step_loss=0.272]\rSteps:  14%|â–ˆâ–        | 45/315 [01:30<08:21,  1.86s/it, lr=0.0001, step_loss=0.266]\rSteps:  15%|â–ˆâ–        | 46/315 [01:31<08:21,  1.86s/it, lr=0.0001, step_loss=0.266]\rSteps:  15%|â–ˆâ–        | 46/315 [01:31<08:21,  1.86s/it, lr=0.0001, step_loss=0.203]\rSteps:  15%|â–ˆâ–        | 47/315 [01:33<08:16,  1.85s/it, lr=0.0001, step_loss=0.203]\rSteps:  15%|â–ˆâ–        | 47/315 [01:33<08:16,  1.85s/it, lr=0.0001, step_loss=0.24] \rSteps:  15%|â–ˆâ–Œ        | 48/315 [01:35<08:14,  1.85s/it, lr=0.0001, step_loss=0.24]\rSteps:  15%|â–ˆâ–Œ        | 48/315 [01:35<08:14,  1.85s/it, lr=0.0001, step_loss=0.261]\rSteps:  16%|â–ˆâ–Œ        | 49/315 [01:37<08:11,  1.85s/it, lr=0.0001, step_loss=0.261]\rSteps:  16%|â–ˆâ–Œ        | 49/315 [01:37<08:11,  1.85s/it, lr=0.0001, step_loss=0.248]\rSteps:  16%|â–ˆâ–Œ        | 50/315 [01:39<08:09,  1.85s/it, lr=0.0001, step_loss=0.248]\rSteps:  16%|â–ˆâ–Œ        | 50/315 [01:39<08:09,  1.85s/it, lr=0.0001, step_loss=0.213]\rSteps:  16%|â–ˆâ–Œ        | 51/315 [01:41<08:10,  1.86s/it, lr=0.0001, step_loss=0.213]\rSteps:  16%|â–ˆâ–Œ        | 51/315 [01:41<08:10,  1.86s/it, lr=0.0001, step_loss=0.234]\rSteps:  17%|â–ˆâ–‹        | 52/315 [01:43<08:08,  1.86s/it, lr=0.0001, step_loss=0.234]\rSteps:  17%|â–ˆâ–‹        | 52/315 [01:43<08:08,  1.86s/it, lr=0.0001, step_loss=0.305]\rSteps:  17%|â–ˆâ–‹        | 53/315 [01:44<08:05,  1.85s/it, lr=0.0001, step_loss=0.305]\rSteps:  17%|â–ˆâ–‹        | 53/315 [01:44<08:05,  1.85s/it, lr=0.0001, step_loss=0.204]\rSteps:  17%|â–ˆâ–‹        | 54/315 [01:46<08:04,  1.86s/it, lr=0.0001, step_loss=0.204]\rSteps:  17%|â–ˆâ–‹        | 54/315 [01:46<08:04,  1.86s/it, lr=0.0001, step_loss=0.291]\rSteps:  17%|â–ˆâ–‹        | 55/315 [01:48<08:04,  1.86s/it, lr=0.0001, step_loss=0.291]\rSteps:  17%|â–ˆâ–‹        | 55/315 [01:48<08:04,  1.86s/it, lr=0.0001, step_loss=0.236]\rSteps:  18%|â–ˆâ–Š        | 56/315 [01:50<08:02,  1.86s/it, lr=0.0001, step_loss=0.236]\rSteps:  18%|â–ˆâ–Š        | 56/315 [01:50<08:02,  1.86s/it, lr=0.0001, step_loss=0.205]\rSteps:  18%|â–ˆâ–Š        | 57/315 [01:52<08:01,  1.87s/it, lr=0.0001, step_loss=0.205]\rSteps:  18%|â–ˆâ–Š        | 57/315 [01:52<08:01,  1.87s/it, lr=0.0001, step_loss=0.25] \rSteps:  18%|â–ˆâ–Š        | 58/315 [01:54<07:59,  1.87s/it, lr=0.0001, step_loss=0.25]\rSteps:  18%|â–ˆâ–Š        | 58/315 [01:54<07:59,  1.87s/it, lr=0.0001, step_loss=0.232]\rSteps:  19%|â–ˆâ–Š        | 59/315 [01:56<07:55,  1.86s/it, lr=0.0001, step_loss=0.232]\rSteps:  19%|â–ˆâ–Š        | 59/315 [01:56<07:55,  1.86s/it, lr=0.0001, step_loss=0.194]\rSteps:  19%|â–ˆâ–‰        | 60/315 [01:57<07:52,  1.85s/it, lr=0.0001, step_loss=0.194]\rSteps:  19%|â–ˆâ–‰        | 60/315 [01:57<07:52,  1.85s/it, lr=0.0001, step_loss=0.178]\rSteps:  19%|â–ˆâ–‰        | 61/315 [01:59<07:48,  1.84s/it, lr=0.0001, step_loss=0.178]\rSteps:  19%|â–ˆâ–‰        | 61/315 [01:59<07:48,  1.84s/it, lr=0.0001, step_loss=0.211]\rSteps:  20%|â–ˆâ–‰        | 62/315 [02:01<07:32,  1.79s/it, lr=0.0001, step_loss=0.211]\rSteps:  20%|â–ˆâ–‰        | 62/315 [02:01<07:32,  1.79s/it, lr=0.0001, step_loss=0.228]\rSteps:  20%|â–ˆâ–ˆ        | 63/315 [02:02<06:16,  1.50s/it, lr=0.0001, step_loss=0.228]\rSteps:  20%|â–ˆâ–ˆ        | 63/315 [02:02<06:16,  1.50s/it, lr=0.0001, step_loss=0.264]05/12/2023 18:42:48 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: cute dragon creature.\n",
            "\n",
            "\rDownloading (â€¦)ain/model_index.json:   0%|          | 0.00/539 [00:00<?, ?B/s]\u001b[A\rDownloading (â€¦)ain/model_index.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 539/539 [00:00<00:00, 2.10MB/s]\n",
            "\n",
            "\rFetching 11 files:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "\rDownloading (â€¦)rocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]\u001b[A\u001b[A\rDownloading (â€¦)rocessor_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 342/342 [00:00<00:00, 1.36MB/s]\n",
            "\n",
            "\rFetching 11 files:   9%|â–‰         | 1/11 [00:00<00:04,  2.12it/s]\u001b[A\rFetching 11 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 23.29it/s]\n",
            "{'sample_max_value', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
            "  warnings.warn(\n",
            "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "\rSteps:  20%|â–ˆâ–ˆ        | 64/315 [02:20<27:44,  6.63s/it, lr=0.0001, step_loss=0.264]\rSteps:  20%|â–ˆâ–ˆ        | 64/315 [02:20<27:44,  6.63s/it, lr=0.0001, step_loss=0.24] \rSteps:  21%|â–ˆâ–ˆ        | 65/315 [02:22<21:41,  5.21s/it, lr=0.0001, step_loss=0.24]\rSteps:  21%|â–ˆâ–ˆ        | 65/315 [02:22<21:41,  5.21s/it, lr=0.0001, step_loss=0.234]\rSteps:  21%|â–ˆâ–ˆ        | 66/315 [02:24<17:26,  4.20s/it, lr=0.0001, step_loss=0.234]\rSteps:  21%|â–ˆâ–ˆ        | 66/315 [02:24<17:26,  4.20s/it, lr=0.0001, step_loss=0.219]\rSteps:  21%|â–ˆâ–ˆâ–       | 67/315 [02:26<14:26,  3.49s/it, lr=0.0001, step_loss=0.219]\rSteps:  21%|â–ˆâ–ˆâ–       | 67/315 [02:26<14:26,  3.49s/it, lr=0.0001, step_loss=0.273]\rSteps:  22%|â–ˆâ–ˆâ–       | 68/315 [02:28<12:20,  3.00s/it, lr=0.0001, step_loss=0.273]\rSteps:  22%|â–ˆâ–ˆâ–       | 68/315 [02:28<12:20,  3.00s/it, lr=0.0001, step_loss=0.25] \rSteps:  22%|â–ˆâ–ˆâ–       | 69/315 [02:30<10:53,  2.66s/it, lr=0.0001, step_loss=0.25]\rSteps:  22%|â–ˆâ–ˆâ–       | 69/315 [02:30<10:53,  2.66s/it, lr=0.0001, step_loss=0.271]\rSteps:  22%|â–ˆâ–ˆâ–       | 70/315 [02:31<09:50,  2.41s/it, lr=0.0001, step_loss=0.271]\rSteps:  22%|â–ˆâ–ˆâ–       | 70/315 [02:31<09:50,  2.41s/it, lr=0.0001, step_loss=0.256]\rSteps:  23%|â–ˆâ–ˆâ–       | 71/315 [02:33<09:07,  2.24s/it, lr=0.0001, step_loss=0.256]\rSteps:  23%|â–ˆâ–ˆâ–       | 71/315 [02:33<09:07,  2.24s/it, lr=0.0001, step_loss=0.244]\rSteps:  23%|â–ˆâ–ˆâ–       | 72/315 [02:35<08:36,  2.12s/it, lr=0.0001, step_loss=0.244]\rSteps:  23%|â–ˆâ–ˆâ–       | 72/315 [02:35<08:36,  2.12s/it, lr=0.0001, step_loss=0.258]\rSteps:  23%|â–ˆâ–ˆâ–       | 73/315 [02:37<08:14,  2.05s/it, lr=0.0001, step_loss=0.258]\rSteps:  23%|â–ˆâ–ˆâ–       | 73/315 [02:37<08:14,  2.05s/it, lr=0.0001, step_loss=0.234]\rSteps:  23%|â–ˆâ–ˆâ–       | 74/315 [02:39<07:59,  1.99s/it, lr=0.0001, step_loss=0.234]\rSteps:  23%|â–ˆâ–ˆâ–       | 74/315 [02:39<07:59,  1.99s/it, lr=0.0001, step_loss=0.175]\rSteps:  24%|â–ˆâ–ˆâ–       | 75/315 [02:41<07:47,  1.95s/it, lr=0.0001, step_loss=0.175]\rSteps:  24%|â–ˆâ–ˆâ–       | 75/315 [02:41<07:47,  1.95s/it, lr=0.0001, step_loss=0.218]\rSteps:  24%|â–ˆâ–ˆâ–       | 76/315 [02:43<07:39,  1.92s/it, lr=0.0001, step_loss=0.218]\rSteps:  24%|â–ˆâ–ˆâ–       | 76/315 [02:43<07:39,  1.92s/it, lr=0.0001, step_loss=0.259]\rSteps:  24%|â–ˆâ–ˆâ–       | 77/315 [02:44<07:32,  1.90s/it, lr=0.0001, step_loss=0.259]\rSteps:  24%|â–ˆâ–ˆâ–       | 77/315 [02:44<07:32,  1.90s/it, lr=0.0001, step_loss=0.184]\rSteps:  25%|â–ˆâ–ˆâ–       | 78/315 [02:46<07:24,  1.88s/it, lr=0.0001, step_loss=0.184]\rSteps:  25%|â–ˆâ–ˆâ–       | 78/315 [02:46<07:24,  1.88s/it, lr=0.0001, step_loss=0.248]\rSteps:  25%|â–ˆâ–ˆâ–Œ       | 79/315 [02:48<07:21,  1.87s/it, lr=0.0001, step_loss=0.248]\rSteps:  25%|â–ˆâ–ˆâ–Œ       | 79/315 [02:48<07:21,  1.87s/it, lr=0.0001, step_loss=0.235]\rSteps:  25%|â–ˆâ–ˆâ–Œ       | 80/315 [02:50<07:18,  1.86s/it, lr=0.0001, step_loss=0.235]\rSteps:  25%|â–ˆâ–ˆâ–Œ       | 80/315 [02:50<07:18,  1.86s/it, lr=0.0001, step_loss=0.279]\rSteps:  26%|â–ˆâ–ˆâ–Œ       | 81/315 [02:52<07:16,  1.87s/it, lr=0.0001, step_loss=0.279]\rSteps:  26%|â–ˆâ–ˆâ–Œ       | 81/315 [02:52<07:16,  1.87s/it, lr=0.0001, step_loss=0.217]\rSteps:  26%|â–ˆâ–ˆâ–Œ       | 82/315 [02:54<07:13,  1.86s/it, lr=0.0001, step_loss=0.217]\rSteps:  26%|â–ˆâ–ˆâ–Œ       | 82/315 [02:54<07:13,  1.86s/it, lr=0.0001, step_loss=0.285]\rSteps:  26%|â–ˆâ–ˆâ–‹       | 83/315 [02:56<07:11,  1.86s/it, lr=0.0001, step_loss=0.285]\rSteps:  26%|â–ˆâ–ˆâ–‹       | 83/315 [02:56<07:11,  1.86s/it, lr=0.0001, step_loss=0.213]\rSteps:  27%|â–ˆâ–ˆâ–‹       | 84/315 [02:57<07:07,  1.85s/it, lr=0.0001, step_loss=0.213]\rSteps:  27%|â–ˆâ–ˆâ–‹       | 84/315 [02:57<07:07,  1.85s/it, lr=0.0001, step_loss=0.268]\rSteps:  27%|â–ˆâ–ˆâ–‹       | 85/315 [02:59<07:06,  1.85s/it, lr=0.0001, step_loss=0.268]\rSteps:  27%|â–ˆâ–ˆâ–‹       | 85/315 [02:59<07:06,  1.85s/it, lr=0.0001, step_loss=0.247]\rSteps:  27%|â–ˆâ–ˆâ–‹       | 86/315 [03:01<07:03,  1.85s/it, lr=0.0001, step_loss=0.247]\rSteps:  27%|â–ˆâ–ˆâ–‹       | 86/315 [03:01<07:03,  1.85s/it, lr=0.0001, step_loss=0.24] \rSteps:  28%|â–ˆâ–ˆâ–Š       | 87/315 [03:03<07:02,  1.85s/it, lr=0.0001, step_loss=0.24]\rSteps:  28%|â–ˆâ–ˆâ–Š       | 87/315 [03:03<07:02,  1.85s/it, lr=0.0001, step_loss=0.256]\rSteps:  28%|â–ˆâ–ˆâ–Š       | 88/315 [03:05<06:59,  1.85s/it, lr=0.0001, step_loss=0.256]\rSteps:  28%|â–ˆâ–ˆâ–Š       | 88/315 [03:05<06:59,  1.85s/it, lr=0.0001, step_loss=0.272]\rSteps:  28%|â–ˆâ–ˆâ–Š       | 89/315 [03:07<06:58,  1.85s/it, lr=0.0001, step_loss=0.272]\rSteps:  28%|â–ˆâ–ˆâ–Š       | 89/315 [03:07<06:58,  1.85s/it, lr=0.0001, step_loss=0.229]\rSteps:  29%|â–ˆâ–ˆâ–Š       | 90/315 [03:08<06:56,  1.85s/it, lr=0.0001, step_loss=0.229]\rSteps:  29%|â–ˆâ–ˆâ–Š       | 90/315 [03:08<06:56,  1.85s/it, lr=0.0001, step_loss=0.248]\rSteps:  29%|â–ˆâ–ˆâ–‰       | 91/315 [03:10<06:55,  1.85s/it, lr=0.0001, step_loss=0.248]\rSteps:  29%|â–ˆâ–ˆâ–‰       | 91/315 [03:10<06:55,  1.85s/it, lr=0.0001, step_loss=0.195]\rSteps:  29%|â–ˆâ–ˆâ–‰       | 92/315 [03:12<06:53,  1.85s/it, lr=0.0001, step_loss=0.195]\rSteps:  29%|â–ˆâ–ˆâ–‰       | 92/315 [03:12<06:53,  1.85s/it, lr=0.0001, step_loss=0.284]\rSteps:  30%|â–ˆâ–ˆâ–‰       | 93/315 [03:14<06:51,  1.85s/it, lr=0.0001, step_loss=0.284]\rSteps:  30%|â–ˆâ–ˆâ–‰       | 93/315 [03:14<06:51,  1.85s/it, lr=0.0001, step_loss=0.236]\rSteps:  30%|â–ˆâ–ˆâ–‰       | 94/315 [03:16<06:48,  1.85s/it, lr=0.0001, step_loss=0.236]\rSteps:  30%|â–ˆâ–ˆâ–‰       | 94/315 [03:16<06:48,  1.85s/it, lr=0.0001, step_loss=0.197]\rSteps:  30%|â–ˆâ–ˆâ–ˆ       | 95/315 [03:18<06:47,  1.85s/it, lr=0.0001, step_loss=0.197]\rSteps:  30%|â–ˆâ–ˆâ–ˆ       | 95/315 [03:18<06:47,  1.85s/it, lr=0.0001, step_loss=0.211]\rSteps:  30%|â–ˆâ–ˆâ–ˆ       | 96/315 [03:20<06:47,  1.86s/it, lr=0.0001, step_loss=0.211]\rSteps:  30%|â–ˆâ–ˆâ–ˆ       | 96/315 [03:20<06:47,  1.86s/it, lr=0.0001, step_loss=0.248]\rSteps:  31%|â–ˆâ–ˆâ–ˆ       | 97/315 [03:21<06:44,  1.86s/it, lr=0.0001, step_loss=0.248]\rSteps:  31%|â–ˆâ–ˆâ–ˆ       | 97/315 [03:21<06:44,  1.86s/it, lr=0.0001, step_loss=0.275]\rSteps:  31%|â–ˆâ–ˆâ–ˆ       | 98/315 [03:23<06:42,  1.85s/it, lr=0.0001, step_loss=0.275]\rSteps:  31%|â–ˆâ–ˆâ–ˆ       | 98/315 [03:23<06:42,  1.85s/it, lr=0.0001, step_loss=0.264]\rSteps:  31%|â–ˆâ–ˆâ–ˆâ–      | 99/315 [03:25<06:41,  1.86s/it, lr=0.0001, step_loss=0.264]\rSteps:  31%|â–ˆâ–ˆâ–ˆâ–      | 99/315 [03:25<06:41,  1.86s/it, lr=0.0001, step_loss=0.259]\rSteps:  32%|â–ˆâ–ˆâ–ˆâ–      | 100/315 [03:27<06:38,  1.86s/it, lr=0.0001, step_loss=0.259]\rSteps:  32%|â–ˆâ–ˆâ–ˆâ–      | 100/315 [03:27<06:38,  1.86s/it, lr=0.0001, step_loss=0.205]\rSteps:  32%|â–ˆâ–ˆâ–ˆâ–      | 101/315 [03:29<06:35,  1.85s/it, lr=0.0001, step_loss=0.205]\rSteps:  32%|â–ˆâ–ˆâ–ˆâ–      | 101/315 [03:29<06:35,  1.85s/it, lr=0.0001, step_loss=0.238]\rSteps:  32%|â–ˆâ–ˆâ–ˆâ–      | 102/315 [03:31<06:34,  1.85s/it, lr=0.0001, step_loss=0.238]\rSteps:  32%|â–ˆâ–ˆâ–ˆâ–      | 102/315 [03:31<06:34,  1.85s/it, lr=0.0001, step_loss=0.277]\rSteps:  33%|â–ˆâ–ˆâ–ˆâ–      | 103/315 [03:33<06:33,  1.85s/it, lr=0.0001, step_loss=0.277]\rSteps:  33%|â–ˆâ–ˆâ–ˆâ–      | 103/315 [03:33<06:33,  1.85s/it, lr=0.0001, step_loss=0.267]\rSteps:  33%|â–ˆâ–ˆâ–ˆâ–      | 104/315 [03:34<06:30,  1.85s/it, lr=0.0001, step_loss=0.267]\rSteps:  33%|â–ˆâ–ˆâ–ˆâ–      | 104/315 [03:34<06:30,  1.85s/it, lr=0.0001, step_loss=0.228]\rSteps:  33%|â–ˆâ–ˆâ–ˆâ–      | 105/315 [03:36<06:28,  1.85s/it, lr=0.0001, step_loss=0.228]\rSteps:  33%|â–ˆâ–ˆâ–ˆâ–      | 105/315 [03:36<06:28,  1.85s/it, lr=0.0001, step_loss=0.253]\rSteps:  34%|â–ˆâ–ˆâ–ˆâ–      | 106/315 [03:38<06:26,  1.85s/it, lr=0.0001, step_loss=0.253]\rSteps:  34%|â–ˆâ–ˆâ–ˆâ–      | 106/315 [03:38<06:26,  1.85s/it, lr=0.0001, step_loss=0.183]\rSteps:  34%|â–ˆâ–ˆâ–ˆâ–      | 107/315 [03:40<06:26,  1.86s/it, lr=0.0001, step_loss=0.183]\rSteps:  34%|â–ˆâ–ˆâ–ˆâ–      | 107/315 [03:40<06:26,  1.86s/it, lr=0.0001, step_loss=0.248]\rSteps:  34%|â–ˆâ–ˆâ–ˆâ–      | 108/315 [03:42<06:24,  1.86s/it, lr=0.0001, step_loss=0.248]\rSteps:  34%|â–ˆâ–ˆâ–ˆâ–      | 108/315 [03:42<06:24,  1.86s/it, lr=0.0001, step_loss=0.262]\rSteps:  35%|â–ˆâ–ˆâ–ˆâ–      | 109/315 [03:44<06:21,  1.85s/it, lr=0.0001, step_loss=0.262]\rSteps:  35%|â–ˆâ–ˆâ–ˆâ–      | 109/315 [03:44<06:21,  1.85s/it, lr=0.0001, step_loss=0.232]\rSteps:  35%|â–ˆâ–ˆâ–ˆâ–      | 110/315 [03:46<06:19,  1.85s/it, lr=0.0001, step_loss=0.232]\rSteps:  35%|â–ˆâ–ˆâ–ˆâ–      | 110/315 [03:46<06:19,  1.85s/it, lr=0.0001, step_loss=0.238]\rSteps:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 111/315 [03:47<06:19,  1.86s/it, lr=0.0001, step_loss=0.238]\rSteps:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 111/315 [03:47<06:19,  1.86s/it, lr=0.0001, step_loss=0.251]\rSteps:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 112/315 [03:49<06:18,  1.86s/it, lr=0.0001, step_loss=0.251]\rSteps:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 112/315 [03:49<06:18,  1.86s/it, lr=0.0001, step_loss=0.222]\rSteps:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 113/315 [03:51<06:16,  1.86s/it, lr=0.0001, step_loss=0.222]\rSteps:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 113/315 [03:51<06:16,  1.86s/it, lr=0.0001, step_loss=0.243]\rSteps:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 114/315 [03:53<06:12,  1.86s/it, lr=0.0001, step_loss=0.243]\rSteps:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 114/315 [03:53<06:12,  1.86s/it, lr=0.0001, step_loss=0.208]\rSteps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 115/315 [03:55<06:11,  1.86s/it, lr=0.0001, step_loss=0.208]\rSteps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 115/315 [03:55<06:11,  1.86s/it, lr=0.0001, step_loss=0.213]\rSteps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 116/315 [03:57<06:10,  1.86s/it, lr=0.0001, step_loss=0.213]\rSteps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 116/315 [03:57<06:10,  1.86s/it, lr=0.0001, step_loss=0.322]\rSteps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 117/315 [03:59<06:08,  1.86s/it, lr=0.0001, step_loss=0.322]\rSteps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 117/315 [03:59<06:08,  1.86s/it, lr=0.0001, step_loss=0.212]\rSteps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 118/315 [04:00<06:06,  1.86s/it, lr=0.0001, step_loss=0.212]\rSteps:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 118/315 [04:00<06:06,  1.86s/it, lr=0.0001, step_loss=0.291]\rSteps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 119/315 [04:02<06:04,  1.86s/it, lr=0.0001, step_loss=0.291]\rSteps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 119/315 [04:02<06:04,  1.86s/it, lr=0.0001, step_loss=0.235]\rSteps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 120/315 [04:04<06:00,  1.85s/it, lr=0.0001, step_loss=0.235]\rSteps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 120/315 [04:04<06:00,  1.85s/it, lr=0.0001, step_loss=0.248]\rSteps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 121/315 [04:06<05:58,  1.85s/it, lr=0.0001, step_loss=0.248]\rSteps:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 121/315 [04:06<05:58,  1.85s/it, lr=0.0001, step_loss=0.215]\rSteps:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 122/315 [04:08<05:56,  1.85s/it, lr=0.0001, step_loss=0.215]\rSteps:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 122/315 [04:08<05:56,  1.85s/it, lr=0.0001, step_loss=0.208]\rSteps:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 123/315 [04:10<05:53,  1.84s/it, lr=0.0001, step_loss=0.208]\rSteps:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 123/315 [04:10<05:53,  1.84s/it, lr=0.0001, step_loss=0.221]\rSteps:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 124/315 [04:12<05:54,  1.86s/it, lr=0.0001, step_loss=0.221]\rSteps:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 124/315 [04:12<05:54,  1.86s/it, lr=0.0001, step_loss=0.241]\rSteps:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 125/315 [04:13<05:40,  1.79s/it, lr=0.0001, step_loss=0.241]\rSteps:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 125/315 [04:13<05:40,  1.79s/it, lr=0.0001, step_loss=0.254]\rSteps:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 126/315 [04:14<04:41,  1.49s/it, lr=0.0001, step_loss=0.254]\rSteps:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 126/315 [04:14<04:41,  1.49s/it, lr=0.0001, step_loss=0.265]05/12/2023 18:45:00 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: cute dragon creature.\n",
            "{'sample_max_value', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio'} was not found in config. Values will be initialized to default values.\n",
            "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "\rSteps:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 127/315 [04:30<18:31,  5.91s/it, lr=0.0001, step_loss=0.265]\rSteps:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 127/315 [04:30<18:31,  5.91s/it, lr=0.0001, step_loss=0.252]\rSteps:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 128/315 [04:32<14:38,  4.70s/it, lr=0.0001, step_loss=0.252]\rSteps:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 128/315 [04:32<14:38,  4.70s/it, lr=0.0001, step_loss=0.246]\rSteps:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 129/315 [04:34<11:54,  3.84s/it, lr=0.0001, step_loss=0.246]\rSteps:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 129/315 [04:34<11:54,  3.84s/it, lr=0.0001, step_loss=0.242]\rSteps:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 130/315 [04:36<10:00,  3.24s/it, lr=0.0001, step_loss=0.242]\rSteps:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 130/315 [04:36<10:00,  3.24s/it, lr=0.0001, step_loss=0.229]\rSteps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 131/315 [04:38<08:39,  2.82s/it, lr=0.0001, step_loss=0.229]\rSteps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 131/315 [04:38<08:39,  2.82s/it, lr=0.0001, step_loss=0.241]\rSteps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 132/315 [04:39<07:44,  2.54s/it, lr=0.0001, step_loss=0.241]\rSteps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 132/315 [04:39<07:44,  2.54s/it, lr=0.0001, step_loss=0.253]\rSteps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 133/315 [04:41<07:03,  2.33s/it, lr=0.0001, step_loss=0.253]\rSteps:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 133/315 [04:41<07:03,  2.33s/it, lr=0.0001, step_loss=0.254]\rSteps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 134/315 [04:43<06:36,  2.19s/it, lr=0.0001, step_loss=0.254]\rSteps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 134/315 [04:43<06:36,  2.19s/it, lr=0.0001, step_loss=0.287]\rSteps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 135/315 [04:45<06:15,  2.09s/it, lr=0.0001, step_loss=0.287]\rSteps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 135/315 [04:45<06:15,  2.09s/it, lr=0.0001, step_loss=0.265]\rSteps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 136/315 [04:47<06:00,  2.01s/it, lr=0.0001, step_loss=0.265]\rSteps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 136/315 [04:47<06:00,  2.01s/it, lr=0.0001, step_loss=0.272]\rSteps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 137/315 [04:49<05:49,  1.96s/it, lr=0.0001, step_loss=0.272]\rSteps:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 137/315 [04:49<05:49,  1.96s/it, lr=0.0001, step_loss=0.295]\rSteps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 138/315 [04:51<05:40,  1.92s/it, lr=0.0001, step_loss=0.295]\rSteps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 138/315 [04:51<05:40,  1.92s/it, lr=0.0001, step_loss=0.228]\rSteps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 139/315 [04:52<05:34,  1.90s/it, lr=0.0001, step_loss=0.228]\rSteps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 139/315 [04:52<05:34,  1.90s/it, lr=0.0001, step_loss=0.229]\rSteps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 140/315 [04:54<05:29,  1.89s/it, lr=0.0001, step_loss=0.229]\rSteps:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 140/315 [04:54<05:29,  1.89s/it, lr=0.0001, step_loss=0.212]\rSteps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 141/315 [04:56<05:26,  1.87s/it, lr=0.0001, step_loss=0.212]\rSteps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 141/315 [04:56<05:26,  1.87s/it, lr=0.0001, step_loss=0.226]\rSteps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 142/315 [04:58<05:23,  1.87s/it, lr=0.0001, step_loss=0.226]\rSteps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 142/315 [04:58<05:23,  1.87s/it, lr=0.0001, step_loss=0.253]\rSteps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 143/315 [05:00<05:21,  1.87s/it, lr=0.0001, step_loss=0.253]\rSteps:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 143/315 [05:00<05:21,  1.87s/it, lr=0.0001, step_loss=0.208]\rSteps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 144/315 [05:02<05:17,  1.86s/it, lr=0.0001, step_loss=0.208]\rSteps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 144/315 [05:02<05:17,  1.86s/it, lr=0.0001, step_loss=0.246]\rSteps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 145/315 [05:03<05:14,  1.85s/it, lr=0.0001, step_loss=0.246]\rSteps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 145/315 [05:03<05:14,  1.85s/it, lr=0.0001, step_loss=0.241]\rSteps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 146/315 [05:05<05:12,  1.85s/it, lr=0.0001, step_loss=0.241]\rSteps:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 146/315 [05:05<05:12,  1.85s/it, lr=0.0001, step_loss=0.242]\rSteps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 147/315 [05:07<05:10,  1.85s/it, lr=0.0001, step_loss=0.242]\rSteps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 147/315 [05:07<05:10,  1.85s/it, lr=0.0001, step_loss=0.218]\rSteps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 148/315 [05:09<05:08,  1.85s/it, lr=0.0001, step_loss=0.218]\rSteps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 148/315 [05:09<05:08,  1.85s/it, lr=0.0001, step_loss=0.245]\rSteps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 149/315 [05:11<05:07,  1.85s/it, lr=0.0001, step_loss=0.245]\rSteps:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 149/315 [05:11<05:07,  1.85s/it, lr=0.0001, step_loss=0.301]\rSteps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 150/315 [05:13<05:06,  1.86s/it, lr=0.0001, step_loss=0.301]\rSteps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 150/315 [05:13<05:06,  1.86s/it, lr=0.0001, step_loss=0.234]\rSteps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 151/315 [05:15<05:03,  1.85s/it, lr=0.0001, step_loss=0.234]\rSteps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 151/315 [05:15<05:03,  1.85s/it, lr=0.0001, step_loss=0.267]\rSteps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 152/315 [05:16<05:01,  1.85s/it, lr=0.0001, step_loss=0.267]\rSteps:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 152/315 [05:16<05:01,  1.85s/it, lr=0.0001, step_loss=0.263]\rSteps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 153/315 [05:18<04:59,  1.85s/it, lr=0.0001, step_loss=0.263]\rSteps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 153/315 [05:18<04:59,  1.85s/it, lr=0.0001, step_loss=0.203]\rSteps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 154/315 [05:20<04:56,  1.84s/it, lr=0.0001, step_loss=0.203]\rSteps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 154/315 [05:20<04:56,  1.84s/it, lr=0.0001, step_loss=0.239]\rSteps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 155/315 [05:22<04:54,  1.84s/it, lr=0.0001, step_loss=0.239]\rSteps:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 155/315 [05:22<04:54,  1.84s/it, lr=0.0001, step_loss=0.233]\rSteps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 156/315 [05:24<04:53,  1.84s/it, lr=0.0001, step_loss=0.233]\rSteps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 156/315 [05:24<04:53,  1.84s/it, lr=0.0001, step_loss=0.269]\rSteps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 157/315 [05:26<04:52,  1.85s/it, lr=0.0001, step_loss=0.269]\rSteps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 157/315 [05:26<04:52,  1.85s/it, lr=0.0001, step_loss=0.225]\rSteps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 158/315 [05:28<04:50,  1.85s/it, lr=0.0001, step_loss=0.225]\rSteps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 158/315 [05:28<04:50,  1.85s/it, lr=0.0001, step_loss=0.259]\rSteps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 159/315 [05:29<04:47,  1.84s/it, lr=0.0001, step_loss=0.259]\rSteps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 159/315 [05:29<04:47,  1.84s/it, lr=0.0001, step_loss=0.243]\rSteps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 160/315 [05:31<04:46,  1.85s/it, lr=0.0001, step_loss=0.243]\rSteps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 160/315 [05:31<04:46,  1.85s/it, lr=0.0001, step_loss=0.201]\rSteps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 161/315 [05:33<04:44,  1.84s/it, lr=0.0001, step_loss=0.201]\rSteps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 161/315 [05:33<04:44,  1.84s/it, lr=0.0001, step_loss=0.225]\rSteps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 162/315 [05:35<04:41,  1.84s/it, lr=0.0001, step_loss=0.225]\rSteps:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 162/315 [05:35<04:41,  1.84s/it, lr=0.0001, step_loss=0.307]\rSteps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 163/315 [05:37<04:40,  1.85s/it, lr=0.0001, step_loss=0.307]\rSteps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 163/315 [05:37<04:40,  1.85s/it, lr=0.0001, step_loss=0.261]\rSteps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 164/315 [05:39<04:40,  1.86s/it, lr=0.0001, step_loss=0.261]\rSteps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 164/315 [05:39<04:40,  1.86s/it, lr=0.0001, step_loss=0.269]\rSteps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 165/315 [05:40<04:39,  1.86s/it, lr=0.0001, step_loss=0.269]\rSteps:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 165/315 [05:40<04:39,  1.86s/it, lr=0.0001, step_loss=0.254]\rSteps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 166/315 [05:42<04:37,  1.86s/it, lr=0.0001, step_loss=0.254]\rSteps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 166/315 [05:42<04:37,  1.86s/it, lr=0.0001, step_loss=0.238]\rSteps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 167/315 [05:44<04:35,  1.86s/it, lr=0.0001, step_loss=0.238]\rSteps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 167/315 [05:44<04:35,  1.86s/it, lr=0.0001, step_loss=0.216]\rSteps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 168/315 [05:46<04:33,  1.86s/it, lr=0.0001, step_loss=0.216]\rSteps:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 168/315 [05:46<04:33,  1.86s/it, lr=0.0001, step_loss=0.163]\rSteps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 169/315 [05:48<04:31,  1.86s/it, lr=0.0001, step_loss=0.163]\rSteps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 169/315 [05:48<04:31,  1.86s/it, lr=0.0001, step_loss=0.212]\rSteps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 170/315 [05:50<04:32,  1.88s/it, lr=0.0001, step_loss=0.212]\rSteps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 170/315 [05:50<04:32,  1.88s/it, lr=0.0001, step_loss=0.271]\rSteps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 171/315 [05:52<04:28,  1.87s/it, lr=0.0001, step_loss=0.271]\rSteps:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 171/315 [05:52<04:28,  1.87s/it, lr=0.0001, step_loss=0.201]\rSteps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 172/315 [05:54<04:25,  1.86s/it, lr=0.0001, step_loss=0.201]\rSteps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 172/315 [05:54<04:25,  1.86s/it, lr=0.0001, step_loss=0.239]\rSteps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 173/315 [05:55<04:23,  1.85s/it, lr=0.0001, step_loss=0.239]\rSteps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 173/315 [05:55<04:23,  1.85s/it, lr=0.0001, step_loss=0.24] \rSteps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 174/315 [05:57<04:20,  1.85s/it, lr=0.0001, step_loss=0.24]\rSteps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 174/315 [05:57<04:20,  1.85s/it, lr=0.0001, step_loss=0.278]\rSteps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 175/315 [05:59<04:18,  1.85s/it, lr=0.0001, step_loss=0.278]\rSteps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 175/315 [05:59<04:18,  1.85s/it, lr=0.0001, step_loss=0.242]\rSteps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 176/315 [06:01<04:16,  1.84s/it, lr=0.0001, step_loss=0.242]\rSteps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 176/315 [06:01<04:16,  1.84s/it, lr=0.0001, step_loss=0.236]\rSteps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 177/315 [06:03<04:15,  1.85s/it, lr=0.0001, step_loss=0.236]\rSteps:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 177/315 [06:03<04:15,  1.85s/it, lr=0.0001, step_loss=0.255]\rSteps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 178/315 [06:05<04:14,  1.86s/it, lr=0.0001, step_loss=0.255]\rSteps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 178/315 [06:05<04:14,  1.86s/it, lr=0.0001, step_loss=0.243]\rSteps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 179/315 [06:06<04:13,  1.86s/it, lr=0.0001, step_loss=0.243]\rSteps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 179/315 [06:06<04:13,  1.86s/it, lr=0.0001, step_loss=0.234]\rSteps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 180/315 [06:08<04:10,  1.86s/it, lr=0.0001, step_loss=0.234]\rSteps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 180/315 [06:08<04:10,  1.86s/it, lr=0.0001, step_loss=0.241]\rSteps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 181/315 [06:10<04:10,  1.87s/it, lr=0.0001, step_loss=0.241]\rSteps:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 181/315 [06:10<04:10,  1.87s/it, lr=0.0001, step_loss=0.229]\rSteps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 182/315 [06:12<04:09,  1.87s/it, lr=0.0001, step_loss=0.229]\rSteps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 182/315 [06:12<04:09,  1.87s/it, lr=0.0001, step_loss=0.259]\rSteps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 183/315 [06:14<04:05,  1.86s/it, lr=0.0001, step_loss=0.259]\rSteps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 183/315 [06:14<04:05,  1.86s/it, lr=0.0001, step_loss=0.212]\rSteps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 184/315 [06:16<04:03,  1.86s/it, lr=0.0001, step_loss=0.212]\rSteps:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 184/315 [06:16<04:03,  1.86s/it, lr=0.0001, step_loss=0.256]\rSteps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 185/315 [06:18<04:01,  1.86s/it, lr=0.0001, step_loss=0.256]\rSteps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 185/315 [06:18<04:01,  1.86s/it, lr=0.0001, step_loss=0.197]\rSteps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 186/315 [06:20<03:59,  1.86s/it, lr=0.0001, step_loss=0.197]\rSteps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 186/315 [06:20<03:59,  1.86s/it, lr=0.0001, step_loss=0.269]\rSteps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 187/315 [06:21<03:57,  1.86s/it, lr=0.0001, step_loss=0.269]\rSteps:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 187/315 [06:21<03:57,  1.86s/it, lr=0.0001, step_loss=0.264]\rSteps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 188/315 [06:23<03:47,  1.79s/it, lr=0.0001, step_loss=0.264]\rSteps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 188/315 [06:23<03:47,  1.79s/it, lr=0.0001, step_loss=0.253]\rSteps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 189/315 [06:24<03:07,  1.49s/it, lr=0.0001, step_loss=0.253]\rSteps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 189/315 [06:24<03:07,  1.49s/it, lr=0.0001, step_loss=0.22] 05/12/2023 18:47:10 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: cute dragon creature.\n",
            "{'sample_max_value', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio'} was not found in config. Values will be initialized to default values.\n",
            "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "\rSteps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 190/315 [06:40<12:18,  5.91s/it, lr=0.0001, step_loss=0.22]\rSteps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 190/315 [06:40<12:18,  5.91s/it, lr=0.0001, step_loss=0.218]\rSteps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 191/315 [06:42<09:42,  4.70s/it, lr=0.0001, step_loss=0.218]\rSteps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 191/315 [06:42<09:42,  4.70s/it, lr=0.0001, step_loss=0.221]\rSteps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 192/315 [06:44<07:53,  3.85s/it, lr=0.0001, step_loss=0.221]\rSteps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 192/315 [06:44<07:53,  3.85s/it, lr=0.0001, step_loss=0.226]\rSteps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 193/315 [06:46<06:36,  3.25s/it, lr=0.0001, step_loss=0.226]\rSteps:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 193/315 [06:46<06:36,  3.25s/it, lr=0.0001, step_loss=0.259]\rSteps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 194/315 [06:47<05:41,  2.82s/it, lr=0.0001, step_loss=0.259]\rSteps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 194/315 [06:47<05:41,  2.82s/it, lr=0.0001, step_loss=0.216]\rSteps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 195/315 [06:49<05:02,  2.52s/it, lr=0.0001, step_loss=0.216]\rSteps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 195/315 [06:49<05:02,  2.52s/it, lr=0.0001, step_loss=0.237]\rSteps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 196/315 [06:51<04:35,  2.32s/it, lr=0.0001, step_loss=0.237]\rSteps:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 196/315 [06:51<04:35,  2.32s/it, lr=0.0001, step_loss=0.236]\rSteps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 197/315 [06:53<04:16,  2.18s/it, lr=0.0001, step_loss=0.236]\rSteps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 197/315 [06:53<04:16,  2.18s/it, lr=0.0001, step_loss=0.23] \rSteps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 198/315 [06:55<04:02,  2.08s/it, lr=0.0001, step_loss=0.23]\rSteps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 198/315 [06:55<04:02,  2.08s/it, lr=0.0001, step_loss=0.211]\rSteps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 199/315 [06:57<03:52,  2.00s/it, lr=0.0001, step_loss=0.211]\rSteps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 199/315 [06:57<03:52,  2.00s/it, lr=0.0001, step_loss=0.259]\rSteps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 200/315 [06:58<03:45,  1.96s/it, lr=0.0001, step_loss=0.259]\rSteps:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 200/315 [06:58<03:45,  1.96s/it, lr=0.0001, step_loss=0.196]\rSteps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 201/315 [07:00<03:39,  1.92s/it, lr=0.0001, step_loss=0.196]\rSteps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 201/315 [07:00<03:39,  1.92s/it, lr=0.0001, step_loss=0.227]\rSteps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 202/315 [07:02<03:35,  1.91s/it, lr=0.0001, step_loss=0.227]\rSteps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 202/315 [07:02<03:35,  1.91s/it, lr=0.0001, step_loss=0.153]\rSteps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 203/315 [07:04<03:31,  1.89s/it, lr=0.0001, step_loss=0.153]\rSteps:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 203/315 [07:04<03:31,  1.89s/it, lr=0.0001, step_loss=0.213]\rSteps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 204/315 [07:06<03:28,  1.88s/it, lr=0.0001, step_loss=0.213]\rSteps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 204/315 [07:06<03:28,  1.88s/it, lr=0.0001, step_loss=0.244]\rSteps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 205/315 [07:08<03:26,  1.88s/it, lr=0.0001, step_loss=0.244]\rSteps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 205/315 [07:08<03:26,  1.88s/it, lr=0.0001, step_loss=0.202]\rSteps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 206/315 [07:10<03:23,  1.87s/it, lr=0.0001, step_loss=0.202]\rSteps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 206/315 [07:10<03:23,  1.87s/it, lr=0.0001, step_loss=0.192]\rSteps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 207/315 [07:11<03:22,  1.87s/it, lr=0.0001, step_loss=0.192]\rSteps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 207/315 [07:11<03:22,  1.87s/it, lr=0.0001, step_loss=0.239]\rSteps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 208/315 [07:13<03:18,  1.86s/it, lr=0.0001, step_loss=0.239]\rSteps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 208/315 [07:13<03:18,  1.86s/it, lr=0.0001, step_loss=0.213]\rSteps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 209/315 [07:15<03:16,  1.85s/it, lr=0.0001, step_loss=0.213]\rSteps:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 209/315 [07:15<03:16,  1.85s/it, lr=0.0001, step_loss=0.238]\rSteps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 210/315 [07:17<03:14,  1.85s/it, lr=0.0001, step_loss=0.238]\rSteps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 210/315 [07:17<03:14,  1.85s/it, lr=0.0001, step_loss=0.236]\rSteps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 211/315 [07:19<03:12,  1.85s/it, lr=0.0001, step_loss=0.236]\rSteps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 211/315 [07:19<03:12,  1.85s/it, lr=0.0001, step_loss=0.244]\rSteps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 212/315 [07:21<03:11,  1.86s/it, lr=0.0001, step_loss=0.244]\rSteps:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 212/315 [07:21<03:11,  1.86s/it, lr=0.0001, step_loss=0.239]\rSteps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 213/315 [07:23<03:10,  1.87s/it, lr=0.0001, step_loss=0.239]\rSteps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 213/315 [07:23<03:10,  1.87s/it, lr=0.0001, step_loss=0.192]\rSteps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 214/315 [07:24<03:08,  1.87s/it, lr=0.0001, step_loss=0.192]\rSteps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 214/315 [07:24<03:08,  1.87s/it, lr=0.0001, step_loss=0.257]\rSteps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 215/315 [07:26<03:05,  1.86s/it, lr=0.0001, step_loss=0.257]\rSteps:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 215/315 [07:26<03:05,  1.86s/it, lr=0.0001, step_loss=0.226]\rSteps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 216/315 [07:28<03:04,  1.86s/it, lr=0.0001, step_loss=0.226]\rSteps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 216/315 [07:28<03:04,  1.86s/it, lr=0.0001, step_loss=0.187]\rSteps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 217/315 [07:30<03:02,  1.86s/it, lr=0.0001, step_loss=0.187]\rSteps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 217/315 [07:30<03:02,  1.86s/it, lr=0.0001, step_loss=0.223]\rSteps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 218/315 [07:32<03:00,  1.86s/it, lr=0.0001, step_loss=0.223]\rSteps:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 218/315 [07:32<03:00,  1.86s/it, lr=0.0001, step_loss=0.287]\rSteps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 219/315 [07:34<02:58,  1.86s/it, lr=0.0001, step_loss=0.287]\rSteps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 219/315 [07:34<02:58,  1.86s/it, lr=0.0001, step_loss=0.214]\rSteps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 220/315 [07:36<02:56,  1.86s/it, lr=0.0001, step_loss=0.214]\rSteps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 220/315 [07:36<02:56,  1.86s/it, lr=0.0001, step_loss=0.218]\rSteps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 221/315 [07:37<02:54,  1.86s/it, lr=0.0001, step_loss=0.218]\rSteps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 221/315 [07:37<02:54,  1.86s/it, lr=0.0001, step_loss=0.225]\rSteps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 222/315 [07:39<02:53,  1.86s/it, lr=0.0001, step_loss=0.225]\rSteps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 222/315 [07:39<02:53,  1.86s/it, lr=0.0001, step_loss=0.215]\rSteps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 223/315 [07:41<02:50,  1.85s/it, lr=0.0001, step_loss=0.215]\rSteps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 223/315 [07:41<02:50,  1.85s/it, lr=0.0001, step_loss=0.189]\rSteps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 224/315 [07:43<02:48,  1.85s/it, lr=0.0001, step_loss=0.189]\rSteps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 224/315 [07:43<02:48,  1.85s/it, lr=0.0001, step_loss=0.292]\rSteps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 225/315 [07:45<02:46,  1.85s/it, lr=0.0001, step_loss=0.292]\rSteps:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 225/315 [07:45<02:46,  1.85s/it, lr=0.0001, step_loss=0.361]\rSteps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 226/315 [07:47<02:44,  1.85s/it, lr=0.0001, step_loss=0.361]\rSteps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 226/315 [07:47<02:44,  1.85s/it, lr=0.0001, step_loss=0.242]\rSteps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 227/315 [07:49<02:42,  1.85s/it, lr=0.0001, step_loss=0.242]\rSteps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 227/315 [07:49<02:42,  1.85s/it, lr=0.0001, step_loss=0.262]\rSteps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 228/315 [07:50<02:41,  1.85s/it, lr=0.0001, step_loss=0.262]\rSteps:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 228/315 [07:50<02:41,  1.85s/it, lr=0.0001, step_loss=0.241]\rSteps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 229/315 [07:52<02:39,  1.85s/it, lr=0.0001, step_loss=0.241]\rSteps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 229/315 [07:52<02:39,  1.85s/it, lr=0.0001, step_loss=0.246]\rSteps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 230/315 [07:54<02:37,  1.85s/it, lr=0.0001, step_loss=0.246]\rSteps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 230/315 [07:54<02:37,  1.85s/it, lr=0.0001, step_loss=0.187]\rSteps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 231/315 [07:56<02:35,  1.85s/it, lr=0.0001, step_loss=0.187]\rSteps:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 231/315 [07:56<02:35,  1.85s/it, lr=0.0001, step_loss=0.263]\rSteps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 232/315 [07:58<02:33,  1.85s/it, lr=0.0001, step_loss=0.263]\rSteps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 232/315 [07:58<02:33,  1.85s/it, lr=0.0001, step_loss=0.23] \rSteps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 233/315 [08:00<02:31,  1.85s/it, lr=0.0001, step_loss=0.23]\rSteps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 233/315 [08:00<02:31,  1.85s/it, lr=0.0001, step_loss=0.239]\rSteps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 234/315 [08:01<02:29,  1.84s/it, lr=0.0001, step_loss=0.239]\rSteps:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 234/315 [08:01<02:29,  1.84s/it, lr=0.0001, step_loss=0.225]\rSteps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 235/315 [08:03<02:27,  1.84s/it, lr=0.0001, step_loss=0.225]\rSteps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 235/315 [08:03<02:27,  1.84s/it, lr=0.0001, step_loss=0.222]\rSteps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 236/315 [08:05<02:25,  1.85s/it, lr=0.0001, step_loss=0.222]\rSteps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 236/315 [08:05<02:25,  1.85s/it, lr=0.0001, step_loss=0.218]\rSteps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 237/315 [08:07<02:24,  1.85s/it, lr=0.0001, step_loss=0.218]\rSteps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 237/315 [08:07<02:24,  1.85s/it, lr=0.0001, step_loss=0.237]\rSteps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 238/315 [08:09<02:22,  1.85s/it, lr=0.0001, step_loss=0.237]\rSteps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 238/315 [08:09<02:22,  1.85s/it, lr=0.0001, step_loss=0.227]\rSteps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 239/315 [08:11<02:20,  1.85s/it, lr=0.0001, step_loss=0.227]\rSteps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 239/315 [08:11<02:20,  1.85s/it, lr=0.0001, step_loss=0.256]\rSteps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 240/315 [08:13<02:18,  1.85s/it, lr=0.0001, step_loss=0.256]\rSteps:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 240/315 [08:13<02:18,  1.85s/it, lr=0.0001, step_loss=0.201]\rSteps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 241/315 [08:14<02:17,  1.85s/it, lr=0.0001, step_loss=0.201]\rSteps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 241/315 [08:14<02:17,  1.85s/it, lr=0.0001, step_loss=0.197]\rSteps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 242/315 [08:16<02:14,  1.85s/it, lr=0.0001, step_loss=0.197]\rSteps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 242/315 [08:16<02:14,  1.85s/it, lr=0.0001, step_loss=0.213]\rSteps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 243/315 [08:18<02:12,  1.84s/it, lr=0.0001, step_loss=0.213]\rSteps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 243/315 [08:18<02:12,  1.84s/it, lr=0.0001, step_loss=0.245]\rSteps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 244/315 [08:20<02:11,  1.85s/it, lr=0.0001, step_loss=0.245]\rSteps:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 244/315 [08:20<02:11,  1.85s/it, lr=0.0001, step_loss=0.267]\rSteps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 245/315 [08:22<02:09,  1.85s/it, lr=0.0001, step_loss=0.267]\rSteps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 245/315 [08:22<02:09,  1.85s/it, lr=0.0001, step_loss=0.24] \rSteps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 246/315 [08:24<02:07,  1.85s/it, lr=0.0001, step_loss=0.24]\rSteps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 246/315 [08:24<02:07,  1.85s/it, lr=0.0001, step_loss=0.252]\rSteps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 247/315 [08:26<02:05,  1.85s/it, lr=0.0001, step_loss=0.252]\rSteps:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 247/315 [08:26<02:05,  1.85s/it, lr=0.0001, step_loss=0.22] \rSteps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 248/315 [08:27<02:04,  1.85s/it, lr=0.0001, step_loss=0.22]\rSteps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 248/315 [08:27<02:04,  1.85s/it, lr=0.0001, step_loss=0.255]\rSteps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 249/315 [08:29<02:01,  1.85s/it, lr=0.0001, step_loss=0.255]\rSteps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 249/315 [08:29<02:01,  1.85s/it, lr=0.0001, step_loss=0.226]\rSteps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 250/315 [08:31<01:59,  1.84s/it, lr=0.0001, step_loss=0.226]\rSteps:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 250/315 [08:31<01:59,  1.84s/it, lr=0.0001, step_loss=0.204]\rSteps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 251/315 [08:33<01:54,  1.78s/it, lr=0.0001, step_loss=0.204]\rSteps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 251/315 [08:33<01:54,  1.78s/it, lr=0.0001, step_loss=0.299]\rSteps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 252/315 [08:33<01:33,  1.48s/it, lr=0.0001, step_loss=0.299]\rSteps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 252/315 [08:33<01:33,  1.48s/it, lr=0.0001, step_loss=0.316]05/12/2023 18:49:20 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: cute dragon creature.\n",
            "{'sample_max_value', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio'} was not found in config. Values will be initialized to default values.\n",
            "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "\rSteps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 253/315 [08:50<06:08,  5.94s/it, lr=0.0001, step_loss=0.316]\rSteps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 253/315 [08:50<06:08,  5.94s/it, lr=0.0001, step_loss=0.243]\rSteps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 254/315 [08:52<04:47,  4.71s/it, lr=0.0001, step_loss=0.243]\rSteps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 254/315 [08:52<04:47,  4.71s/it, lr=0.0001, step_loss=0.257]\rSteps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 255/315 [08:54<03:51,  3.86s/it, lr=0.0001, step_loss=0.257]\rSteps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 255/315 [08:54<03:51,  3.86s/it, lr=0.0001, step_loss=0.245]\rSteps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 256/315 [08:55<03:11,  3.24s/it, lr=0.0001, step_loss=0.245]\rSteps:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 256/315 [08:55<03:11,  3.24s/it, lr=0.0001, step_loss=0.228]\rSteps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 257/315 [08:57<02:43,  2.83s/it, lr=0.0001, step_loss=0.228]\rSteps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 257/315 [08:57<02:43,  2.83s/it, lr=0.0001, step_loss=0.193]\rSteps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 258/315 [08:59<02:24,  2.54s/it, lr=0.0001, step_loss=0.193]\rSteps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 258/315 [08:59<02:24,  2.54s/it, lr=0.0001, step_loss=0.215]\rSteps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 259/315 [09:01<02:10,  2.33s/it, lr=0.0001, step_loss=0.215]\rSteps:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 259/315 [09:01<02:10,  2.33s/it, lr=0.0001, step_loss=0.205]\rSteps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 260/315 [09:03<02:00,  2.18s/it, lr=0.0001, step_loss=0.205]\rSteps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 260/315 [09:03<02:00,  2.18s/it, lr=0.0001, step_loss=0.27] \rSteps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 261/315 [09:05<01:52,  2.08s/it, lr=0.0001, step_loss=0.27]\rSteps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 261/315 [09:05<01:52,  2.08s/it, lr=0.0001, step_loss=0.26]\rSteps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 262/315 [09:06<01:46,  2.01s/it, lr=0.0001, step_loss=0.26]\rSteps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 262/315 [09:06<01:46,  2.01s/it, lr=0.0001, step_loss=0.244]\rSteps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 263/315 [09:08<01:41,  1.96s/it, lr=0.0001, step_loss=0.244]\rSteps:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 263/315 [09:08<01:41,  1.96s/it, lr=0.0001, step_loss=0.257]\rSteps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 264/315 [09:10<01:38,  1.93s/it, lr=0.0001, step_loss=0.257]\rSteps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 264/315 [09:10<01:38,  1.93s/it, lr=0.0001, step_loss=0.23] \rSteps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 265/315 [09:12<01:35,  1.90s/it, lr=0.0001, step_loss=0.23]\rSteps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 265/315 [09:12<01:35,  1.90s/it, lr=0.0001, step_loss=0.208]\rSteps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 266/315 [09:14<01:32,  1.88s/it, lr=0.0001, step_loss=0.208]\rSteps:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 266/315 [09:14<01:32,  1.88s/it, lr=0.0001, step_loss=0.237]\rSteps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 267/315 [09:16<01:29,  1.87s/it, lr=0.0001, step_loss=0.237]\rSteps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 267/315 [09:16<01:29,  1.87s/it, lr=0.0001, step_loss=0.217]\rSteps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 268/315 [09:18<01:27,  1.87s/it, lr=0.0001, step_loss=0.217]\rSteps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 268/315 [09:18<01:27,  1.87s/it, lr=0.0001, step_loss=0.233]\rSteps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 269/315 [09:19<01:26,  1.88s/it, lr=0.0001, step_loss=0.233]\rSteps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 269/315 [09:19<01:26,  1.88s/it, lr=0.0001, step_loss=0.206]\rSteps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 270/315 [09:21<01:23,  1.87s/it, lr=0.0001, step_loss=0.206]\rSteps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 270/315 [09:21<01:23,  1.87s/it, lr=0.0001, step_loss=0.223]\rSteps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 271/315 [09:23<01:22,  1.86s/it, lr=0.0001, step_loss=0.223]\rSteps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 271/315 [09:23<01:22,  1.86s/it, lr=0.0001, step_loss=0.182]\rSteps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 272/315 [09:25<01:20,  1.87s/it, lr=0.0001, step_loss=0.182]\rSteps:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 272/315 [09:25<01:20,  1.87s/it, lr=0.0001, step_loss=0.27] \rSteps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 273/315 [09:27<01:18,  1.86s/it, lr=0.0001, step_loss=0.27]\rSteps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 273/315 [09:27<01:18,  1.86s/it, lr=0.0001, step_loss=0.257]\rSteps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 274/315 [09:29<01:15,  1.85s/it, lr=0.0001, step_loss=0.257]\rSteps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 274/315 [09:29<01:15,  1.85s/it, lr=0.0001, step_loss=0.218]\rSteps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 275/315 [09:30<01:13,  1.84s/it, lr=0.0001, step_loss=0.218]\rSteps:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 275/315 [09:30<01:13,  1.84s/it, lr=0.0001, step_loss=0.222]\rSteps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 276/315 [09:32<01:11,  1.84s/it, lr=0.0001, step_loss=0.222]\rSteps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 276/315 [09:32<01:11,  1.84s/it, lr=0.0001, step_loss=0.234]\rSteps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 277/315 [09:34<01:10,  1.85s/it, lr=0.0001, step_loss=0.234]\rSteps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 277/315 [09:34<01:10,  1.85s/it, lr=0.0001, step_loss=0.259]\rSteps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 278/315 [09:36<01:08,  1.86s/it, lr=0.0001, step_loss=0.259]\rSteps:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 278/315 [09:36<01:08,  1.86s/it, lr=0.0001, step_loss=0.188]\rSteps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 279/315 [09:38<01:06,  1.85s/it, lr=0.0001, step_loss=0.188]\rSteps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 279/315 [09:38<01:06,  1.85s/it, lr=0.0001, step_loss=0.17] \rSteps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 280/315 [09:40<01:04,  1.85s/it, lr=0.0001, step_loss=0.17]\rSteps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 280/315 [09:40<01:04,  1.85s/it, lr=0.0001, step_loss=0.207]\rSteps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 281/315 [09:42<01:02,  1.85s/it, lr=0.0001, step_loss=0.207]\rSteps:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 281/315 [09:42<01:02,  1.85s/it, lr=0.0001, step_loss=0.183]\rSteps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 282/315 [09:43<01:01,  1.85s/it, lr=0.0001, step_loss=0.183]\rSteps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 282/315 [09:43<01:01,  1.85s/it, lr=0.0001, step_loss=0.256]\rSteps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 283/315 [09:45<00:59,  1.86s/it, lr=0.0001, step_loss=0.256]\rSteps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 283/315 [09:45<00:59,  1.86s/it, lr=0.0001, step_loss=0.167]\rSteps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 284/315 [09:47<00:57,  1.86s/it, lr=0.0001, step_loss=0.167]\rSteps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 284/315 [09:47<00:57,  1.86s/it, lr=0.0001, step_loss=0.185]\rSteps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 285/315 [09:49<00:55,  1.86s/it, lr=0.0001, step_loss=0.185]\rSteps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 285/315 [09:49<00:55,  1.86s/it, lr=0.0001, step_loss=0.219]\rSteps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 286/315 [09:51<00:53,  1.85s/it, lr=0.0001, step_loss=0.219]\rSteps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 286/315 [09:51<00:53,  1.85s/it, lr=0.0001, step_loss=0.226]\rSteps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 287/315 [09:53<00:51,  1.85s/it, lr=0.0001, step_loss=0.226]\rSteps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 287/315 [09:53<00:51,  1.85s/it, lr=0.0001, step_loss=0.257]\rSteps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 288/315 [09:55<00:49,  1.85s/it, lr=0.0001, step_loss=0.257]\rSteps:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 288/315 [09:55<00:49,  1.85s/it, lr=0.0001, step_loss=0.234]\rSteps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 289/315 [09:56<00:48,  1.85s/it, lr=0.0001, step_loss=0.234]\rSteps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 289/315 [09:56<00:48,  1.85s/it, lr=0.0001, step_loss=0.221]\rSteps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 290/315 [09:58<00:46,  1.85s/it, lr=0.0001, step_loss=0.221]\rSteps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 290/315 [09:58<00:46,  1.85s/it, lr=0.0001, step_loss=0.232]\rSteps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 291/315 [10:00<00:44,  1.86s/it, lr=0.0001, step_loss=0.232]\rSteps:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 291/315 [10:00<00:44,  1.86s/it, lr=0.0001, step_loss=0.234]\rSteps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 292/315 [10:02<00:42,  1.86s/it, lr=0.0001, step_loss=0.234]\rSteps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 292/315 [10:02<00:42,  1.86s/it, lr=0.0001, step_loss=0.231]\rSteps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 293/315 [10:04<00:40,  1.86s/it, lr=0.0001, step_loss=0.231]\rSteps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 293/315 [10:04<00:40,  1.86s/it, lr=0.0001, step_loss=0.241]\rSteps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 294/315 [10:06<00:38,  1.85s/it, lr=0.0001, step_loss=0.241]\rSteps:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 294/315 [10:06<00:38,  1.85s/it, lr=0.0001, step_loss=0.226]\rSteps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 295/315 [10:08<00:36,  1.85s/it, lr=0.0001, step_loss=0.226]\rSteps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 295/315 [10:08<00:36,  1.85s/it, lr=0.0001, step_loss=0.275]\rSteps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 296/315 [10:09<00:35,  1.86s/it, lr=0.0001, step_loss=0.275]\rSteps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 296/315 [10:09<00:35,  1.86s/it, lr=0.0001, step_loss=0.225]\rSteps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 297/315 [10:11<00:33,  1.85s/it, lr=0.0001, step_loss=0.225]\rSteps:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 297/315 [10:11<00:33,  1.85s/it, lr=0.0001, step_loss=0.245]\rSteps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 298/315 [10:13<00:31,  1.86s/it, lr=0.0001, step_loss=0.245]\rSteps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 298/315 [10:13<00:31,  1.86s/it, lr=0.0001, step_loss=0.256]\rSteps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 299/315 [10:15<00:29,  1.85s/it, lr=0.0001, step_loss=0.256]\rSteps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 299/315 [10:15<00:29,  1.85s/it, lr=0.0001, step_loss=0.212]\rSteps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 300/315 [10:17<00:27,  1.85s/it, lr=0.0001, step_loss=0.212]\rSteps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 300/315 [10:17<00:27,  1.85s/it, lr=0.0001, step_loss=0.236]\rSteps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 301/315 [10:19<00:25,  1.85s/it, lr=0.0001, step_loss=0.236]\rSteps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 301/315 [10:19<00:25,  1.85s/it, lr=0.0001, step_loss=0.208]\rSteps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 302/315 [10:21<00:24,  1.85s/it, lr=0.0001, step_loss=0.208]\rSteps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 302/315 [10:21<00:24,  1.85s/it, lr=0.0001, step_loss=0.248]\rSteps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 303/315 [10:22<00:22,  1.85s/it, lr=0.0001, step_loss=0.248]\rSteps:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 303/315 [10:22<00:22,  1.85s/it, lr=0.0001, step_loss=0.232]\rSteps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 304/315 [10:24<00:20,  1.85s/it, lr=0.0001, step_loss=0.232]\rSteps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 304/315 [10:24<00:20,  1.85s/it, lr=0.0001, step_loss=0.259]\rSteps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 305/315 [10:26<00:18,  1.85s/it, lr=0.0001, step_loss=0.259]\rSteps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 305/315 [10:26<00:18,  1.85s/it, lr=0.0001, step_loss=0.259]\rSteps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 306/315 [10:28<00:16,  1.85s/it, lr=0.0001, step_loss=0.259]\rSteps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 306/315 [10:28<00:16,  1.85s/it, lr=0.0001, step_loss=0.222]\rSteps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 307/315 [10:30<00:14,  1.84s/it, lr=0.0001, step_loss=0.222]\rSteps:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 307/315 [10:30<00:14,  1.84s/it, lr=0.0001, step_loss=0.303]\rSteps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 308/315 [10:32<00:12,  1.85s/it, lr=0.0001, step_loss=0.303]\rSteps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 308/315 [10:32<00:12,  1.85s/it, lr=0.0001, step_loss=0.262]\rSteps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 309/315 [10:33<00:11,  1.84s/it, lr=0.0001, step_loss=0.262]\rSteps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 309/315 [10:33<00:11,  1.84s/it, lr=0.0001, step_loss=0.208]\rSteps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 310/315 [10:35<00:09,  1.85s/it, lr=0.0001, step_loss=0.208]\rSteps:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 310/315 [10:35<00:09,  1.85s/it, lr=0.0001, step_loss=0.252]\rSteps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 311/315 [10:37<00:07,  1.85s/it, lr=0.0001, step_loss=0.252]\rSteps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 311/315 [10:37<00:07,  1.85s/it, lr=0.0001, step_loss=0.253]\rSteps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 312/315 [10:39<00:05,  1.86s/it, lr=0.0001, step_loss=0.253]\rSteps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 312/315 [10:39<00:05,  1.86s/it, lr=0.0001, step_loss=0.229]\rSteps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 313/315 [10:41<00:03,  1.85s/it, lr=0.0001, step_loss=0.229]\rSteps:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 313/315 [10:41<00:03,  1.85s/it, lr=0.0001, step_loss=0.232]\rSteps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 314/315 [10:43<00:01,  1.80s/it, lr=0.0001, step_loss=0.232]\rSteps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 314/315 [10:43<00:01,  1.80s/it, lr=0.0001, step_loss=0.237]\rSteps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 315/315 [10:43<00:00,  1.49s/it, lr=0.0001, step_loss=0.237]\rSteps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 315/315 [10:43<00:00,  1.49s/it, lr=0.0001, step_loss=0.206]05/12/2023 18:51:30 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: cute dragon creature.\n",
            "{'sample_max_value', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio'} was not found in config. Values will be initialized to default values.\n",
            "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "Model weights saved in sd-diffusiondb-pixelart-model-lora/pytorch_lora_weights.bin\n",
            "\n",
            "\rUpload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "\rpytorch_lora_weights.bin:   0%|          | 0.00/3.42M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\rpytorch_lora_weights.bin:   0%|          | 8.19k/3.42M [00:00<04:44, 12.0kB/s]\u001b[A\u001b[A\n",
            "\n",
            "\rpytorch_lora_weights.bin:   3%|â–         | 115k/3.42M [00:00<00:20, 160kB/s]  \u001b[A\u001b[A\n",
            "\n",
            "\rpytorch_lora_weights.bin:   5%|â–Œ         | 180k/3.42M [00:01<00:15, 202kB/s]\u001b[A\u001b[A\n",
            "\n",
            "\rpytorch_lora_weights.bin:   9%|â–‰         | 303k/3.42M [00:01<00:10, 311kB/s]\u001b[A\u001b[A\n",
            "\n",
            "\rpytorch_lora_weights.bin:  15%|â–ˆâ–        | 508k/3.42M [00:01<00:05, 498kB/s]\u001b[A\u001b[A\n",
            "\n",
            "\rpytorch_lora_weights.bin:  26%|â–ˆâ–ˆâ–‹       | 901k/3.42M [00:01<00:02, 840kB/s]\u001b[A\u001b[A\n",
            "\n",
            "\rpytorch_lora_weights.bin:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.29M/3.42M [00:02<00:01, 1.16MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\rpytorch_lora_weights.bin:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.86M/3.42M [00:02<00:00, 1.60MB/s]\u001b[A\u001b[A\rpytorch_lora_weights.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.42M/3.42M [00:03<00:00, 1.13MB/s]\n",
            "\n",
            "\rUpload 1 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.32s/it]\u001b[A\rUpload 1 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.32s/it]\n",
            "{'sample_max_value', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio'} was not found in config. Values will be initialized to default values.\n",
            "{'addition_embed_type', 'mid_block_only_cross_attention', 'resnet_time_scale_shift', 'conv_out_kernel', 'time_embedding_act_fn', 'mid_block_type', 'resnet_out_scale_factor', 'addition_embed_type_num_heads', 'timestep_post_act', 'cross_attention_norm', 'conv_in_kernel', 'resnet_skip_time_act', 'encoder_hid_dim', 'time_embedding_dim', 'time_embedding_type', 'projection_class_embeddings_input_dim', 'class_embeddings_concat', 'time_cond_proj_dim', 'class_embed_type'} was not found in config. Values will be initialized to default values.\n",
            "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "\r  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
            "\r  3%|â–         | 1/30 [00:00<00:05,  5.50it/s]\u001b[A\n",
            "\r  7%|â–‹         | 2/30 [00:00<00:04,  6.09it/s]\u001b[A\n",
            "\r 10%|â–ˆ         | 3/30 [00:00<00:04,  6.31it/s]\u001b[A\n",
            "\r 13%|â–ˆâ–        | 4/30 [00:00<00:04,  6.41it/s]\u001b[A\n",
            "\r 17%|â–ˆâ–‹        | 5/30 [00:00<00:03,  6.46it/s]\u001b[A\n",
            "\r 20%|â–ˆâ–ˆ        | 6/30 [00:00<00:03,  6.49it/s]\u001b[A\n",
            "\r 23%|â–ˆâ–ˆâ–       | 7/30 [00:01<00:03,  6.51it/s]\u001b[A\n",
            "\r 27%|â–ˆâ–ˆâ–‹       | 8/30 [00:01<00:03,  6.53it/s]\u001b[A\n",
            "\r 30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:01<00:03,  6.54it/s]\u001b[A\n",
            "\r 33%|â–ˆâ–ˆâ–ˆâ–      | 10/30 [00:01<00:03,  6.55it/s]\u001b[A\n",
            "\r 37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:01<00:02,  6.55it/s]\u001b[A\n",
            "\r 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:01<00:02,  6.56it/s]\u001b[A\n",
            "\r 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/30 [00:02<00:02,  6.57it/s]\u001b[A\n",
            "\r 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:02<00:02,  6.57it/s]\u001b[A\n",
            "\r 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:02<00:02,  6.57it/s]\u001b[A\n",
            "\r 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 16/30 [00:02<00:02,  6.57it/s]\u001b[A\n",
            "\r 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:02<00:01,  6.58it/s]\u001b[A\n",
            "\r 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:02<00:01,  6.58it/s]\u001b[A\n",
            "\r 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 19/30 [00:02<00:01,  6.58it/s]\u001b[A\n",
            "\r 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:03<00:01,  6.59it/s]\u001b[A\n",
            "\r 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:03<00:01,  6.59it/s]\u001b[A\n",
            "\r 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 22/30 [00:03<00:01,  6.59it/s]\u001b[A\n",
            "\r 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:03<00:01,  6.60it/s]\u001b[A\n",
            "\r 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:03<00:00,  6.60it/s]\u001b[A\n",
            "\r 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 25/30 [00:03<00:00,  6.61it/s]\u001b[A\n",
            "\r 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:03<00:00,  6.61it/s]\u001b[A\n",
            "\r 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:04<00:00,  6.62it/s]\u001b[A\n",
            "\r 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 28/30 [00:04<00:00,  6.63it/s]\u001b[A\n",
            "\r 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:04<00:00,  6.64it/s]\u001b[A\n",
            "\r100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.65it/s]\u001b[A\r100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.55it/s]\n",
            "\n",
            "\r  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
            "\r  3%|â–         | 1/30 [00:00<00:04,  6.66it/s]\u001b[A\n",
            "\r  7%|â–‹         | 2/30 [00:00<00:04,  6.64it/s]\u001b[A\n",
            "\r 10%|â–ˆ         | 3/30 [00:00<00:04,  6.64it/s]\u001b[A\n",
            "\r 13%|â–ˆâ–        | 4/30 [00:00<00:03,  6.64it/s]\u001b[A\n",
            "\r 17%|â–ˆâ–‹        | 5/30 [00:00<00:03,  6.64it/s]\u001b[A\n",
            "\r 20%|â–ˆâ–ˆ        | 6/30 [00:00<00:03,  6.65it/s]\u001b[A\n",
            "\r 23%|â–ˆâ–ˆâ–       | 7/30 [00:01<00:03,  6.65it/s]\u001b[A\n",
            "\r 27%|â–ˆâ–ˆâ–‹       | 8/30 [00:01<00:03,  6.64it/s]\u001b[A\n",
            "\r 30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:01<00:03,  6.64it/s]\u001b[A\n",
            "\r 33%|â–ˆâ–ˆâ–ˆâ–      | 10/30 [00:01<00:03,  6.63it/s]\u001b[A\n",
            "\r 37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:01<00:02,  6.63it/s]\u001b[A\n",
            "\r 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:01<00:02,  6.63it/s]\u001b[A\n",
            "\r 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/30 [00:01<00:02,  6.63it/s]\u001b[A\n",
            "\r 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:02<00:02,  6.63it/s]\u001b[A\n",
            "\r 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:02<00:02,  6.63it/s]\u001b[A\n",
            "\r 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 16/30 [00:02<00:02,  6.63it/s]\u001b[A\n",
            "\r 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:02<00:01,  6.63it/s]\u001b[A\n",
            "\r 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:02<00:01,  6.63it/s]\u001b[A\n",
            "\r 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 19/30 [00:02<00:01,  6.63it/s]\u001b[A\n",
            "\r 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:03<00:01,  6.63it/s]\u001b[A\n",
            "\r 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:03<00:01,  6.64it/s]\u001b[A\n",
            "\r 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 22/30 [00:03<00:01,  6.64it/s]\u001b[A\n",
            "\r 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:03<00:01,  6.64it/s]\u001b[A\n",
            "\r 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:03<00:00,  6.64it/s]\u001b[A\n",
            "\r 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 25/30 [00:03<00:00,  6.64it/s]\u001b[A\n",
            "\r 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:03<00:00,  6.65it/s]\u001b[A\n",
            "\r 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:04<00:00,  6.65it/s]\u001b[A\n",
            "\r 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 28/30 [00:04<00:00,  6.65it/s]\u001b[A\n",
            "\r 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:04<00:00,  6.65it/s]\u001b[A\n",
            "\r100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.65it/s]\u001b[A\r100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.64it/s]\n",
            "\n",
            "\r  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
            "\r  3%|â–         | 1/30 [00:00<00:04,  6.64it/s]\u001b[A\n",
            "\r  7%|â–‹         | 2/30 [00:00<00:04,  6.62it/s]\u001b[A\n",
            "\r 10%|â–ˆ         | 3/30 [00:00<00:04,  6.61it/s]\u001b[A\n",
            "\r 13%|â–ˆâ–        | 4/30 [00:00<00:03,  6.60it/s]\u001b[A\n",
            "\r 17%|â–ˆâ–‹        | 5/30 [00:00<00:03,  6.60it/s]\u001b[A\n",
            "\r 20%|â–ˆâ–ˆ        | 6/30 [00:00<00:03,  6.59it/s]\u001b[A\n",
            "\r 23%|â–ˆâ–ˆâ–       | 7/30 [00:01<00:03,  6.59it/s]\u001b[A\n",
            "\r 27%|â–ˆâ–ˆâ–‹       | 8/30 [00:01<00:03,  6.59it/s]\u001b[A\n",
            "\r 30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:01<00:03,  6.59it/s]\u001b[A\n",
            "\r 33%|â–ˆâ–ˆâ–ˆâ–      | 10/30 [00:01<00:03,  6.59it/s]\u001b[A\n",
            "\r 37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:01<00:02,  6.59it/s]\u001b[A\n",
            "\r 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:01<00:02,  6.59it/s]\u001b[A\n",
            "\r 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/30 [00:01<00:02,  6.59it/s]\u001b[A\n",
            "\r 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:02<00:02,  6.60it/s]\u001b[A\n",
            "\r 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:02<00:02,  6.60it/s]\u001b[A\n",
            "\r 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 16/30 [00:02<00:02,  6.59it/s]\u001b[A\n",
            "\r 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:02<00:01,  6.60it/s]\u001b[A\n",
            "\r 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:02<00:01,  6.59it/s]\u001b[A\n",
            "\r 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 19/30 [00:02<00:01,  6.60it/s]\u001b[A\n",
            "\r 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:03<00:01,  6.59it/s]\u001b[A\n",
            "\r 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:03<00:01,  6.59it/s]\u001b[A\n",
            "\r 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 22/30 [00:03<00:01,  6.59it/s]\u001b[A\n",
            "\r 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:03<00:01,  6.59it/s]\u001b[A\n",
            "\r 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:03<00:00,  6.60it/s]\u001b[A\n",
            "\r 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 25/30 [00:03<00:00,  6.60it/s]\u001b[A\n",
            "\r 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:03<00:00,  6.60it/s]\u001b[A\n",
            "\r 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:04<00:00,  6.61it/s]\u001b[A\n",
            "\r 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 28/30 [00:04<00:00,  6.62it/s]\u001b[A\n",
            "\r 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:04<00:00,  6.62it/s]\u001b[A\n",
            "\r100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.61it/s]\u001b[A\r100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.60it/s]\n",
            "\n",
            "\r  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
            "\r  3%|â–         | 1/30 [00:00<00:04,  6.63it/s]\u001b[A\n",
            "\r  7%|â–‹         | 2/30 [00:00<00:04,  6.60it/s]\u001b[A\n",
            "\r 10%|â–ˆ         | 3/30 [00:00<00:04,  6.58it/s]\u001b[A\n",
            "\r 13%|â–ˆâ–        | 4/30 [00:00<00:03,  6.57it/s]\u001b[A\n",
            "\r 17%|â–ˆâ–‹        | 5/30 [00:00<00:03,  6.57it/s]\u001b[A\n",
            "\r 20%|â–ˆâ–ˆ        | 6/30 [00:00<00:03,  6.57it/s]\u001b[A\n",
            "\r 23%|â–ˆâ–ˆâ–       | 7/30 [00:01<00:03,  6.57it/s]\u001b[A\n",
            "\r 27%|â–ˆâ–ˆâ–‹       | 8/30 [00:01<00:03,  6.57it/s]\u001b[A\n",
            "\r 30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:01<00:03,  6.57it/s]\u001b[A\n",
            "\r 33%|â–ˆâ–ˆâ–ˆâ–      | 10/30 [00:01<00:03,  6.57it/s]\u001b[A\n",
            "\r 37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:01<00:02,  6.57it/s]\u001b[A\n",
            "\r 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:01<00:02,  6.57it/s]\u001b[A\n",
            "\r 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/30 [00:01<00:02,  6.57it/s]\u001b[A\n",
            "\r 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:02<00:02,  6.57it/s]\u001b[A\n",
            "\r 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:02<00:02,  6.57it/s]\u001b[A\n",
            "\r 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 16/30 [00:02<00:02,  6.58it/s]\u001b[A\n",
            "\r 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:02<00:01,  6.58it/s]\u001b[A\n",
            "\r 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:02<00:01,  6.59it/s]\u001b[A\n",
            "\r 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 19/30 [00:02<00:01,  6.59it/s]\u001b[A\n",
            "\r 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:03<00:01,  6.60it/s]\u001b[A\n",
            "\r 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:03<00:01,  6.59it/s]\u001b[A\n",
            "\r 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 22/30 [00:03<00:01,  6.59it/s]\u001b[A\n",
            "\r 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:03<00:01,  6.60it/s]\u001b[A\n",
            "\r 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:03<00:00,  6.60it/s]\u001b[A\n",
            "\r 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 25/30 [00:03<00:00,  6.60it/s]\u001b[A\n",
            "\r 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:03<00:00,  6.60it/s]\u001b[A\n",
            "\r 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:04<00:00,  6.61it/s]\u001b[A\n",
            "\r 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 28/30 [00:04<00:00,  6.61it/s]\u001b[A\n",
            "\r 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:04<00:00,  6.62it/s]\u001b[A\n",
            "\r100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.63it/s]\u001b[A\r100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.59it/s]\n",
            "wandb: Waiting for W&B process to finish... (success).\n",
            "wandb: - 17.448 MB of 20.958 MB uploaded (0.000 MB deduped)\rwandb: \\ 17.448 MB of 20.958 MB uploaded (0.000 MB deduped)\rwandb: | 17.448 MB of 20.958 MB uploaded (0.000 MB deduped)\rwandb: / 17.448 MB of 20.958 MB uploaded (0.000 MB deduped)\rwandb: - 17.448 MB of 20.958 MB uploaded (0.000 MB deduped)\rwandb: \\ 17.448 MB of 20.958 MB uploaded (0.000 MB deduped)\rwandb: | 17.448 MB of 20.958 MB uploaded (0.000 MB deduped)\rwandb: \n",
            "wandb: Run history:\n",
            "wandb: train_loss â–„â–†â–…â–‚â–„â–‚â–†â–ƒâ–…â–†â–‡â–‡â–†â–…â–„â–†â–†â–‡â–†â–†â–ƒâ–â–…â–†â–„â–ƒâ–„â–‚â–ˆâ–…â–ƒâ–†â–…â–…â–‡â–ƒâ–…â–„â–†â–…\n",
            "wandb: \n",
            "wandb: Run summary:\n",
            "wandb: train_loss 0.20583\n",
            "wandb: \n",
            "wandb: ğŸš€ View run dutiful-sunset-6 at: https://wandb.ai/rahul96jain/text2image-fine-tune/runs/gjqwiuda\n",
            "wandb: Synced 5 W&B file(s), 24 media file(s), 2 artifact file(s) and 0 other file(s)\n",
            "wandb: Find logs at: ./wandb/run-20230512_184045-gjqwiuda/logs\n",
            "/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py:2088: UserWarning: Run (gjqwiuda) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
            "  lambda data: self._console_raw_callback(\"stderr\", data),\n",
            "\rSteps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 315/315 [11:40<00:00,  2.22s/it, lr=0.0001, step_loss=0.206]\n"
          ]
        }
      ]
    }
  ]
}